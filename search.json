[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Impact of Brief Mindfulness Training on Judgments of Confidence, Anxiety, and Difficulty While Answering Physics Questions",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#osf-links",
    "href": "index.html#osf-links",
    "title": "The Impact of Brief Mindfulness Training on Judgments of Confidence, Anxiety, and Difficulty While Answering Physics Questions",
    "section": "OSF Links",
    "text": "OSF Links\n\nProject Home\nProject Overview\nPreregistration Plan\nPhysics Task Materials",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "chapters/01-changes-from-preregistration.html",
    "href": "chapters/01-changes-from-preregistration.html",
    "title": "1  Changes From the Preregistration",
    "section": "",
    "text": "1.1 Wording Adjustments\nAll changes below are in reference to Preregistration 3 – Physics Task Outcomes (https://doi.org/10.17605/OSF.IO/SA9W2).\nThe preregistration refers to the physics tasks as “problem solving.” We replaced this term with the phrase, “answering physics questions.” While all of our tasks assessed processes involved in problem solving (i.e., problem categorization and conceptual understanding), the term “problem solving” is more commonly used among physics teachers in reference to straightforward quantitative problems. Therefore, we decided that “answering physics questions” was a more accurate description of our tasks.",
    "crumbs": [
      "Supplementary Descriptive Text",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Changes From the Preregistration</span>"
    ]
  },
  {
    "objectID": "chapters/01-changes-from-preregistration.html#model-specifications",
    "href": "chapters/01-changes-from-preregistration.html#model-specifications",
    "title": "1  Changes From the Preregistration",
    "section": "1.2 Model Specifications",
    "text": "1.2 Model Specifications\nFor RQ1, Hypotheses 1-3 in the main text: Instead of predicting outcomes at posttest while controlling for baseline (Hypotheses 4-6 in the preregistration), we used mixed-effects models that included Timepoint as a fixed effect, with baseline coded as 0 and posttest coded as 1. This allowed us to effectively test multiple hypotheses with fewer statistical models: baseline differences outlined in Preregistration, Aim 1, and effects of mindfulness training outlined in Preregistration, Aim 2. The advantage of this is that we were able to simultaneously reduce the likelihood of committing type 1 error (by running fewer individual tests) and lessen the burden on the reader. Both methods produced the same pattern of results (see Model 1 for each judgment type in Section 9.5 for results using linear models as described in the preregistration).",
    "crumbs": [
      "Supplementary Descriptive Text",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Changes From the Preregistration</span>"
    ]
  },
  {
    "objectID": "chapters/01-changes-from-preregistration.html#gender-moderation",
    "href": "chapters/01-changes-from-preregistration.html#gender-moderation",
    "title": "1  Changes From the Preregistration",
    "section": "1.3 Gender Moderation",
    "text": "1.3 Gender Moderation\nWhile we expected gender to be an important covariate, we did not preregister it as a moderator. Therefore, it is explicitly presented as exploratory in the main text. Results of the mixed-effects models without gender included as a moderator can be found here in Supplementary Table 8.2, Supplementary Table 8.3, and Supplementary Table 8.4. Results of the mediation analyses without gender moderation can be found in Section 9.5. In both cases, the general pattern of results is the same. Including gender as a moderator helped bring our results into greater focus. For example, it revealed that overall effects of the intervention on judgments of confidence and anxiety were driven by women and non-binary students, while effects for judgements of difficulty were stable across genders.",
    "crumbs": [
      "Supplementary Descriptive Text",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Changes From the Preregistration</span>"
    ]
  },
  {
    "objectID": "chapters/01-changes-from-preregistration.html#additional-control-variables",
    "href": "chapters/01-changes-from-preregistration.html#additional-control-variables",
    "title": "1  Changes From the Preregistration",
    "section": "1.4 Additional Control Variables",
    "text": "1.4 Additional Control Variables\nWe added several additional control variables to the models that were not included in the preregistration. First, unlike what is specified in the preregistration, we included baseline psychological threat as a predictor in all the models, whereas it is only included in Aim 1: H1-H2 in the preregistration (testing baseline associations). Because our final models simultaneously tested the hypotheses in Aim 1 (baseline associations) and Aim 2 (effects of mindfulness on outcomes at posttest), we included it to control for overall effects of pre-intervention levels of psychological threat. We also included item-level accuracy as a covariate in the models to rule out potential confounding effects on perceptions. Including these variables had no meaningful impact on the results, as shown in Supplementary Table 8.2, Supplementary Table 8.3, and Supplementary Table 8.4.",
    "crumbs": [
      "Supplementary Descriptive Text",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Changes From the Preregistration</span>"
    ]
  },
  {
    "objectID": "chapters/01-changes-from-preregistration.html#accuracy-and-learning-outcomes",
    "href": "chapters/01-changes-from-preregistration.html#accuracy-and-learning-outcomes",
    "title": "1  Changes From the Preregistration",
    "section": "1.5 Accuracy and Learning Outcomes",
    "text": "1.5 Accuracy and Learning Outcomes\nFinally, the analyses of accuracy performance and preparation for future learning outcomes described in the preregistration are not included in the main text. We did not find any effects of mindfulness training on these outcomes (preregistered hypotheses 1, 4, and 5) or any mediation effects (preregistered hypotheses 7 and 8). Therefore, we chose to remove the details of these analyses from the main text to narrow the scope of the paper. Those results are reported in these materials in Supplementary Table 10.1 and Supplementary Table 10.2.",
    "crumbs": [
      "Supplementary Descriptive Text",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Changes From the Preregistration</span>"
    ]
  },
  {
    "objectID": "chapters/02-physics-tasks-descriptions.html",
    "href": "chapters/02-physics-tasks-descriptions.html",
    "title": "2  Examples of Physics Task Items",
    "section": "",
    "text": "2.1 Physics Tasks, Part 1: Quantitative Problem Solving\nStudents were provided with a general equation sheet for reference and asked to solve a single quantitative problem. They were instructed to use a blank sheet of paper to write out their work and final answer. The quantitative problems were developed for this study by Drs. Melanie Good and Eric Kuo (See Supplementary Figure 2.1).",
    "crumbs": [
      "Supplementary Descriptive Text",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Examples of Physics Task Items</span>"
    ]
  },
  {
    "objectID": "chapters/02-physics-tasks-descriptions.html#physics-tasks-part-1-quantitative-problem-solving",
    "href": "chapters/02-physics-tasks-descriptions.html#physics-tasks-part-1-quantitative-problem-solving",
    "title": "2  Examples of Physics Task Items",
    "section": "",
    "text": "Supplementary Figure 2.1: Sample Quantitative Physics Task Item",
    "crumbs": [
      "Supplementary Descriptive Text",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Examples of Physics Task Items</span>"
    ]
  },
  {
    "objectID": "chapters/02-physics-tasks-descriptions.html#physics-tasks-part-2-problem-categorization",
    "href": "chapters/02-physics-tasks-descriptions.html#physics-tasks-part-2-problem-categorization",
    "title": "2  Examples of Physics Task Items",
    "section": "2.2 Physics Tasks, Part 2: Problem Categorization",
    "text": "2.2 Physics Tasks, Part 2: Problem Categorization\nThis part consisted of five items adapted from, and similar to, those used in Hardiman, Dufresne, and Mestre (1989). For each item, a model problem was presented along with two alternative problems. Students were instructed to select the alternative which is solved most like the model problem (deep structure match). Four out of five items contained surface feature distractors, meaning that there were surface features in the incorrect alternative which resembled the model problem (See Supplementary Figure 2.2).\n\n\n\nSupplementary Figure 2.2: Sample Categorization Physics Task Item\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSupplementary Figure 2.2: At first glance, the model problem and alternative 2 appear similar because they both involve projectiles, but this similarity is a surface-level distractor. The model problem and alternative 1 are asking for final velocity and can be solved using conservation of energy, while alternative 2 requires the use of kinematics to solve for time. Therefore, the correct response is alternative 1.",
    "crumbs": [
      "Supplementary Descriptive Text",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Examples of Physics Task Items</span>"
    ]
  },
  {
    "objectID": "chapters/02-physics-tasks-descriptions.html#physics-tasks-part-3-conceptual-questions-qualitative-problem-solving",
    "href": "chapters/02-physics-tasks-descriptions.html#physics-tasks-part-3-conceptual-questions-qualitative-problem-solving",
    "title": "2  Examples of Physics Task Items",
    "section": "2.3 Physics Tasks, Part 3: Conceptual Questions (Qualitative Problem Solving)",
    "text": "2.3 Physics Tasks, Part 3: Conceptual Questions (Qualitative Problem Solving)\nThis part consisted of three multiple-choice questions (See Supplementary Figure 2.3), followed by one open-ended problem (See Supplementary Figure 2.4). For each multiple-choice question, participants were also asked to provide a brief explanation for their choice. The open-ended problem was a word problem in which participants were asked to explain a solution.\n\n\n\n\n\n\nSupplementary Figure 2.3: Multiple-Choice Item\n\n\n\n\n\n\n\n\n\n\n\nSupplementary Figure 2.4: Open-Ended Item\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSupplementary Figure 2.3: Qualitative multiple-choice item: The correct answer is option A because the frictional force is proportional to the normal force, which is equal to the weight force. Therefore, the only way to increase the frictional force is to increase the mass; Supplementary Figure 2.4: Qualitative open response item: Newton’s second law states that \\(F_{net}=\\frac{Δp}{Δt}\\). Airbags reduce the force (outcome) of a collision by increasing the time it takes for the collision to occur (mechanism). Half credit was given to responses that mentioned either force or time correctly, and full credit was given to responses that mentioned both force and time.",
    "crumbs": [
      "Supplementary Descriptive Text",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Examples of Physics Task Items</span>"
    ]
  },
  {
    "objectID": "chapters/02-physics-tasks-descriptions.html#physics-tasks-part-4-preparation-for-future-learning",
    "href": "chapters/02-physics-tasks-descriptions.html#physics-tasks-part-4-preparation-for-future-learning",
    "title": "2  Examples of Physics Task Items",
    "section": "2.4 Physics Tasks, Part 4: Preparation for Future Learning",
    "text": "2.4 Physics Tasks, Part 4: Preparation for Future Learning\nThe Preparation for Future Learning (PFL) task (Belenky and Nokes-Malach 2012; Schwartz and Martin 2004) is a 3-part learning activity that participants completed only at posttest. Physics problems used in the learning activity were taken from Weinlader et al. (2019). The first part consisted of solving a difficult multiple-choice problem which required comparing the trajectories of two projectiles and predicting which would hit their target first (see Supplementary Figure 2.5). In the second part, a learning resource explaining the first problem was provided. The resource contained an explanation of why the correct answer choice was valid, and why each incorrect answer was not. The third part consisted of a novel problem with similar surface features to the first problem but had a different correct response. Answering correctly required applying the underlying principles of the first problem to a different set of conditions. Each of the two problems required both a multiple-choice answer as well as a short-answer explanation for the selected choice.\n\n\n\nSupplementary Figure 2.5: Sample Preparation for Future Learning Task Item\n\n\n\n\n\n\n\n\n\n\n\n\nBelenky, Daniel M, and Timothy J Nokes-Malach. 2012. “Motivation and Transfer: The Role of Mastery-Approach Goals in Preparation for Future Learning.” The Journal of the Learning Sciences 21 (3): 399–432. https://doi.org/10.1080/10508406.2011.651232.\n\n\nHardiman, Pamela Thibodeau, Robert Dufresne, and Jose P Mestre. 1989. “The Relation Between Problem Categorization and Problem Solving Among Experts and Novices.” Memory & Cognition 17 (5): 627–38.\n\n\nSchwartz, Daniel L, and Taylor Martin. 2004. “Inventing to Prepare for Future Learning: The Hidden Efficiency of Encouraging Original Student Production in Statistics Instruction.” Cognition and Instruction 22 (2): 129–84.\n\n\nWeinlader, Nolan K., Eric Kuo, Benjamin M. Rottman, and Timothy J. Nokes-Malach. 2019. “A New Approach for Uncovering Student Resources with Multiple-Choice Questions.” In, 621–26. American Association of Physics Teachers. https://doi.org/10.1119/perc.2019.pr.Weinlader.",
    "crumbs": [
      "Supplementary Descriptive Text",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Examples of Physics Task Items</span>"
    ]
  },
  {
    "objectID": "chapters/03-physics-tasks-scoring.html",
    "href": "chapters/03-physics-tasks-scoring.html",
    "title": "\n3  Scoring Procedure For Physics Learning and Performance Outcomes\n",
    "section": "",
    "text": "3.1 Physics Assessment, Part 1: Quantitative Problem Solving\nFor all measures which required qualitative coding or scoring, the following procedure was used: First, a rubric was developed through group discussion with the research team. Then, a portion of the responses were coded independently by a minimum of two coders. Discrepancies from the first round of coding were reviewed by the team and the rubric was revised as needed. The remaining responses were coded again in full by two coders and all discrepancies were resolved in the presence of a third coder. Any responses that could not be easily resolved were brought to the research team for review. For each measure that was coded or scored, we report two inter-rater reliability statistics, one for each round of coding.\nThe quantitative problems (one for each test version) were scored according to a rubric developed by the research team. Partial credit was given for incomplete or partially correct solutions. Responses from baseline and posttest were combined and randomized within each test version before scoring, and team members were blinded to condition. The intraclass correlation for the first round of coding was .74 for version A (20 responses) and .8 for version B (29 responses). The intraclass correlation for the remaining solutions were .7 for version A (129 responses), and .94 for version B (117 responses). Final scores were calculated by taking the proportion of points earned out of the total possible points. Three responses on the posttest quantitative problem-solving task were removed from analysis. In one case, it was clear there was additional work cropped out of the uploaded image which could not be scored; in another, the uploaded file was a duplicate of their baseline file; and in the last case the handwriting was deemed illegible by all of the raters.",
    "crumbs": [
      "Supplementary Descriptive Text",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Scoring Procedure For Physics Learning and Performance Outcomes</span>"
    ]
  },
  {
    "objectID": "chapters/03-physics-tasks-scoring.html#physics-assessment-part-2-problem-categorization",
    "href": "chapters/03-physics-tasks-scoring.html#physics-assessment-part-2-problem-categorization",
    "title": "\n3  Scoring Procedure For Physics Learning and Performance Outcomes\n",
    "section": "\n3.2 Physics Assessment, Part 2: Problem Categorization",
    "text": "3.2 Physics Assessment, Part 2: Problem Categorization\nIndividual items were scored dichotomously as 0 (incorrect) or 1 (correct). Final scores were calculated by taking the average accuracy across the five categorization items.",
    "crumbs": [
      "Supplementary Descriptive Text",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Scoring Procedure For Physics Learning and Performance Outcomes</span>"
    ]
  },
  {
    "objectID": "chapters/03-physics-tasks-scoring.html#physics-assessment-part-3-qualitative-problem-solving",
    "href": "chapters/03-physics-tasks-scoring.html#physics-assessment-part-3-qualitative-problem-solving",
    "title": "\n3  Scoring Procedure For Physics Learning and Performance Outcomes\n",
    "section": "\n3.3 Physics Assessment, Part 3: Qualitative Problem Solving",
    "text": "3.3 Physics Assessment, Part 3: Qualitative Problem Solving\nThe three multiple-choice questions were scored dichotomously as 0 (incorrect) or 1 (correct). For the purposes of the current work and questions we did not analyze the open-response explanations for the multiple-choice questions. The open-ended word problem was coded and scored by the research team. Responses were awarded a maximum of two points: one point for each component of the correct explanation. For example, the question in test version B described a scenario in which an elevator cable snaps, and the emergency friction brakes are engaged. The student was asked to describe the types of energy transfer which occur in this scenario. One point was given for describing gravitational potential energy being converted to kinetic energy, and another for describing kinetic energy being converted to thermal and sound energy due to work done by friction. Similar to the quantitative problem, all responses were combined and randomized across timepoints, and experimental condition was removed from the data before scoring. The weighted Kappa for the first round of coding was .36 for version A (50 responses), and .58 for version B (53 responses). The weighted Kappas for the second round of coding were .71 for version A (99 responses), and .74 for version B (95 responses). When calculating the final score, the open-ended word problem was weighted equal to the multiple-choice, such that two-point responses were scored as a 1 and one-point responses were scored as a .5. Final scores for qualitative problem solving were calculated by taking the mean score of all the items.",
    "crumbs": [
      "Supplementary Descriptive Text",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Scoring Procedure For Physics Learning and Performance Outcomes</span>"
    ]
  },
  {
    "objectID": "chapters/03-physics-tasks-scoring.html#physics-assessment-part-4-preparation-for-future-learning-pfl",
    "href": "chapters/03-physics-tasks-scoring.html#physics-assessment-part-4-preparation-for-future-learning-pfl",
    "title": "\n3  Scoring Procedure For Physics Learning and Performance Outcomes\n",
    "section": "\n3.4 Physics Assessment, Part 4: Preparation for Future Learning (PFL)",
    "text": "3.4 Physics Assessment, Part 4: Preparation for Future Learning (PFL)\nThere were two components to the response for each of the two PFL questions: multiple-choice selection and open-response explanation. We defined correctness on the PFL as selecting the correct multiple choice response option and reasoning correctly in the open-response explanation. For both questions, student reasoning was considered correct if they mentioned the relative maximum heights or initial y velocities of the two trajectories as a justification for their answer, or if they mentioned that the y component was most important for determining time in the air. These questions were the only ones for which we did not complete two separate rounds of coding because we build directly on our past work with a similar population (Weinlader et al. 2019). Otherwise, the coding procedure was identical to the others. Responses were randomized and coders were blinded to condition. Both PFL questions were coded in full by two coders as either correct or incorrect. The unweighted Kappa for both of the PFL questions was .88. All discrepancies were resolved through discussion in the presence of a third coder.\n\n\n\nSupplementary Table 3.1: Summary of Item Types and Scoring Scales by Outcome\n\n\n\n\n Outcome Measure \n    Items and Measurement \n    Scoring \n  \n\nPhysics Problem Solving Performance\n\n Part 1: Quantitative Problem Solving \n    1 item, open response \n    Points earned/points possible, continuous from 0 to 1 \n  \n\n Part 2: Problem Categorization \n    5 items, forced-choice \n    Mean score, continuous from 0 to 1 \n  \n\n Part 3: Qualitative Problem Solving \n    3 multiple-choice, 1 open response \n    Mean score, continuous from 0 to 1 \n  \nPreparation for Future Learning\n\n Part 4: Preparation for Future Learning \n    2 items, multiple-choice with open response explanation \n    Dichotomous, 0 or 1: 1 = Correct multiple choice response & attends to y component correctly in explanation \n  \nMomentary Item-Level Perceptions\n\n Confidence \n    1 item, measured repeatedly \n    Continuous from 1 to 6 \n  \n\n Anxiety \n    1 item, measured repeatedly \n    Continuous from 1 to 6 \n  \n\n Difficulty \n    1 item, measured repeatedly \n    Continuous from 1 to 6 \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nWeinlader, Nolan K., Eric Kuo, Benjamin M. Rottman, and Timothy J. Nokes-Malach. 2019. “A New Approach for Uncovering Student Resources with Multiple-Choice Questions.” In, 621–26. American Association of Physics Teachers. https://doi.org/10.1119/perc.2019.pr.Weinlader.",
    "crumbs": [
      "Supplementary Descriptive Text",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Scoring Procedure For Physics Learning and Performance Outcomes</span>"
    ]
  },
  {
    "objectID": "chapters/04-clustering-variables.html",
    "href": "chapters/04-clustering-variables.html",
    "title": "4  Clustering Variables Examined but Not Included",
    "section": "",
    "text": "We explored the particular class section that the participants were recruited from as a potential covariate. There were many aspects of the classes that were homogeneous: all instructors were required to adhere to the same set of pre-defined learning objectives, and beginning in cohort 3’s semester (during which over half our sample participated), the department instituted measures which required classes to synchronize exam schedules, recitation quizzes, homework systems, and textbooks. Nevertheless, each class has its own variation in terms of the number of students enrolled, days and times they meet, the amount of synchronous vs. asynchronous activities, and the students that select to be in those classes. Furthermore, all instructors have idiosyncratic aspects to their teaching methods and can have different demands and resources in the class.  The inclusion of class by instructor as a covariate was explored, but ultimately not included. Seven instructors taught the physics classes represented in our sample. Most instructors taught one class except one instructor who taught two, and another who taught 4 (total of eleven classes).\nThe number of students associated with each class ranged from 5 to 21 (M = 13.5, SD = 5.01). Theoretically, it made sense to include class and instructor as nested random intercept terms because we wanted to account for clustering by class and instructor, but we did not have any predictions about specific classes or professors. However, the ICC for class and instructor was at or very close to zero in all the models. This indicates that statistically, observations within classes and instructors were no more similar to each other than to observations from different classes and instructors. We also conducted a visual inspection of the all the focal study variables by instructor and did not detect any differences that appeared systematic. Based on these analyses, we did not include class or instructor in the reported models.",
    "crumbs": [
      "Supplementary Descriptive Text",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Clustering Variables Examined but Not Included</span>"
    ]
  },
  {
    "objectID": "chapters/05-data-setup.html",
    "href": "chapters/05-data-setup.html",
    "title": "\n5  Data and Environment Setup\n",
    "section": "",
    "text": "5.1 Source Setup Script\nIn order to run the code included in this book, you first need to run “/R/setup-script.R” to install/load required packages and read the data. The data are located in “/data/preregistration_3_data_public.csv”.\nShow/Hide Codesource(\"R/setup-script.R\")",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data and Environment Setup</span>"
    ]
  },
  {
    "objectID": "chapters/05-data-setup.html#session-info",
    "href": "chapters/05-data-setup.html#session-info",
    "title": "\n5  Data and Environment Setup\n",
    "section": "\n5.2 Session Info",
    "text": "5.2 Session Info\n\nShow/Hide CodesessionInfo()\n\nR version 4.5.0 (2025-04-11)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sonoma 14.6.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] lubridate_1.9.4    forcats_1.0.0      stringr_1.5.1      dplyr_1.1.4       \n [5] purrr_1.0.4        readr_2.1.5        tidyr_1.3.1        tibble_3.2.1      \n [9] tidyverse_2.0.0    ggpubr_0.6.0       rstatix_0.7.2      showtext_0.9-7    \n[13] showtextdb_3.0     sysfonts_0.8.9     patchwork_1.3.0    GGally_2.2.1      \n[17] ggplot2_3.5.2      sjtable2df_0.0.4   sjlabelled_1.2.0   sjmisc_2.8.10     \n[21] sjPlot_2.8.17      lmerTest_3.1-3     lme4_1.1-37        mediation_4.5.0   \n[25] sandwich_3.1-1     mvtnorm_1.3-3      Matrix_1.7-3       MASS_7.3-65       \n[29] gvlma_1.0.0.3      performance_0.15.1 kableExtra_1.4.0   pacman_0.5.1      \n\nloaded via a namespace (and not attached):\n [1] Rdpack_2.6.4        gridExtra_2.3       rlang_1.1.6        \n [4] magrittr_2.0.3      compiler_4.5.0      systemfonts_1.2.2  \n [7] vctrs_0.6.5         crayon_1.5.3        pkgconfig_2.0.3    \n[10] fastmap_1.2.0       backports_1.5.0     rmarkdown_2.29     \n[13] tzdb_0.5.0          nloptr_2.2.1        bit_4.6.0          \n[16] xfun_0.52           jsonlite_2.0.0      ggeffects_2.2.1    \n[19] parallel_4.5.0      broom_1.0.8         cluster_2.1.8.1    \n[22] R6_2.6.1            stringi_1.8.7       RColorBrewer_1.1-3 \n[25] car_3.1-3           boot_1.3-31         rpart_4.1.24       \n[28] numDeriv_2016.8-1.1 Rcpp_1.0.14         knitr_1.50         \n[31] zoo_1.8-14          base64enc_0.1-3     splines_4.5.0      \n[34] nnet_7.3-20         timechange_0.3.0    tidyselect_1.2.1   \n[37] rstudioapi_0.17.1   abind_1.4-8         yaml_2.3.10        \n[40] codetools_0.2-20    curl_6.2.2          lattice_0.22-7     \n[43] plyr_1.8.9          withr_3.0.2         evaluate_1.0.3     \n[46] foreign_0.8-90      archive_1.1.12      ggstats_0.9.0      \n[49] xml2_1.3.8          lpSolve_5.6.23      pillar_1.10.2      \n[52] carData_3.0-5       checkmate_2.3.2     reformulas_0.4.0   \n[55] insight_1.4.2       generics_0.1.3      vroom_1.6.5        \n[58] hms_1.1.3           scales_1.4.0        minqa_1.2.8        \n[61] glue_1.8.0          Hmisc_5.2-3         tools_4.5.0        \n[64] data.table_1.17.8   ggsignif_0.6.4      grid_4.5.0         \n[67] rbibutils_2.3       datawizard_1.2.0    colorspace_2.1-1   \n[70] nlme_3.1-168        htmlTable_2.4.3     Formula_1.2-5      \n[73] cli_3.6.5           viridisLite_0.4.2   svglite_2.1.3      \n[76] sjstats_0.19.0      gtable_0.3.6        digest_0.6.37      \n[79] htmlwidgets_1.6.4   farver_2.1.2        htmltools_0.5.8.1  \n[82] lifecycle_1.0.4     bit64_4.6.0-1",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data and Environment Setup</span>"
    ]
  },
  {
    "objectID": "chapters/05-data-setup.html#datasets",
    "href": "chapters/05-data-setup.html#datasets",
    "title": "\n5  Data and Environment Setup\n",
    "section": "\n5.3 Datasets",
    "text": "5.3 Datasets\nThe analyses in the main text are run using two forms of the data, one for each research question / analysis type. Summaries of the data charactaristics are described below.\nRQ1 Data\nThese data are in long format - (22 items x 149 participants - 3 NA values) x 3 judgments per item = 9825 observations.\n\n\n\n\n\n\nNote\n\n\n\nthe variable perception is equivalent to “judgment” in the manuscript.\n\n\n\nShow/Hide Codedata_rq1 |&gt; glimpse()\n\nRows: 9,825\nColumns: 17\n$ Participant           &lt;chr&gt; \"mvU3yT4uTFpW58Z0\", \"mvU3yT4uTFpW58Z0\", \"mvU3yT4…\n$ Condition             &lt;fct&gt; Control, Control, Control, Control, Control, Con…\n$ Gender                &lt;fct&gt; Men, Men, Men, Men, Men, Men, Men, Men, Men, Men…\n$ Cohort                &lt;fct&gt; Cohort 1, Cohort 1, Cohort 1, Cohort 1, Cohort 1…\n$ Timepoint             &lt;fct&gt; Baseline, Baseline, Baseline, Baseline, Baseline…\n$ Semester_Week         &lt;dbl&gt; 1.912752, 1.912752, 1.912752, 1.912752, 1.912752…\n$ Test_Version          &lt;fct&gt; B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, …\n$ Part                  &lt;chr&gt; \"Quantitative\", \"Quantitative\", \"Quantitative\", …\n$ Question              &lt;dbl&gt; 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, …\n$ Item                  &lt;chr&gt; \"B01\", \"B01\", \"B01\", \"B02\", \"B02\", \"B02\", \"B03\",…\n$ Score                 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, …\n$ `Item-Level Accuracy` &lt;fct&gt; Incorrect, Incorrect, Incorrect, Incorrect, Inco…\n$ Accuracy_Raw          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, …\n$ Baseline_Threat       &lt;dbl&gt; 1.63132, 1.63132, 1.63132, 1.63132, 1.63132, 1.6…\n$ EMA_Threat            &lt;dbl&gt; 3.416667, 3.416667, 3.416667, 3.416667, 3.416667…\n$ perception            &lt;fct&gt; Confidence, Anxiety, Difficulty, Confidence, Anx…\n$ rating                &lt;dbl&gt; 1, 6, 6, 5, 6, 2, 4, 6, 3, 5, 6, 4, 5, 6, 4, 4, …\n\n\nParticipant-Level Variables\n\nShow/Hide Coderq1_participants &lt;- data_rq1 |&gt;\n  select(\n    Participant,\n    Condition,\n    Gender,\n    Cohort,\n    Semester_Week,\n    Baseline_Threat\n  ) |&gt;\n  unique()\n\nrq1_participants |&gt;\n  select(-where(is.numeric)) |&gt;\n  summary()\n\n Participant              Condition                  Gender        Cohort  \n Length:149         Control    :73   Men                :66   Cohort 1:61  \n Class :character   Mindfulness:76   Women or Non-binary:83   Cohort 2:16  \n Mode  :character                                             Cohort 3:72  \n\nShow/Hide Coderq1_participants |&gt;\n  get_summary_stats(show = c(\"min\", \"max\", \"mean\", \"sd\"))\n\n\n\n\nvariable\nn\nmin\nmax\nmean\nsd\n\n\n\nSemester_Week\n149\n-4.087\n4.913\n0\n2.790\n\n\nBaseline_Threat\n149\n-3.102\n2.865\n0\n1.297\n\n\n\n\n\n\nItem (Observation)-Level Variables\n\n\n\n\n\n\nNote\n\n\n\nScore includes values between 0 and 1 since 4 of the items (A01, B01, A10, and B10) were open-ended and could be awarded partial credit. Item-Level Accuracy (factor version) and Accuracy_Raw (numeric version) were derived from Score to compare incorrect responses to those that were at least partially correct (Score &gt; 0).\n\n\n\nShow/Hide Codedata_rq1 |&gt;\n  select(\n    Item,\n    Timepoint,\n    Test_Version,\n    `Item-Level Accuracy`,\n    perception\n  ) |&gt;\n  summary()\n\n     Item              Timepoint    Test_Version Item-Level Accuracy\n Length:9825        Baseline:4470   A:4908       Incorrect:5547     \n Class :character   Posttest:5355   B:4917       Correct  :4278     \n Mode  :character                                                   \n      perception  \n Confidence:3275  \n Anxiety   :3275  \n Difficulty:3275  \n\nShow/Hide Codedata_rq1 |&gt;\n  select(\n    Score,\n    Accuracy_Raw,\n    rating\n  ) |&gt;\n  get_summary_stats(show = c(\"min\", \"max\", \"mean\", \"sd\"))\n\n\n\n\nvariable\nn\nmin\nmax\nmean\nsd\n\n\n\nScore\n9825\n0\n1\n0.404\n0.478\n\n\nAccuracy_Raw\n9825\n0\n1\n0.435\n0.496\n\n\nrating\n9825\n1\n6\n3.474\n1.408\n\n\n\n\n\n\nRQ2 Data\nData are in wide format, so everything varies at the participant level. Judgment ratings and accuracy scores are averaged at baseline and posttest. Continuous variables are standardized and numeric dummy variables with contrast coding are created for Cohort because the mediation package does not accept factors with contrast coding, but this has no bearing on the results. One participant’s data was removed because they did not complete any EMA surveys.\n\nShow/Hide Codedata_rq2 |&gt; glimpse()\n\nRows: 148\nColumns: 21\n$ Participant           &lt;chr&gt; \"mvU3yT4uTFpW58Z0\", \"bTvjXPvFUSNyAt5t\", \"hx3UKKU…\n$ Condition             &lt;fct&gt; Control, Control, Control, Control, Control, Con…\n$ Gender                &lt;fct&gt; Men, Men, Men, Women or Non-binary, Men, Women o…\n$ Cohort                &lt;fct&gt; Cohort 1, Cohort 1, Cohort 1, Cohort 1, Cohort 3…\n$ Semester_Week         &lt;dbl&gt; 0.6786886, 0.6786886, 0.6786886, 1.0374240, -0.7…\n$ Baseline_Threat       &lt;dbl&gt; 1.25100904, -0.75116043, -1.05918650, 1.89273003…\n$ EMA_Threat            &lt;dbl&gt; 1.55096412, 1.29550795, -0.95250627, 1.29550795,…\n$ Baseline_n_items      &lt;int&gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, …\n$ Posttest_n_items      &lt;int&gt; 12, 12, 12, 12, 12, 12, 11, 12, 12, 12, 12, 12, …\n$ Baseline_Score        &lt;dbl&gt; -0.31125932, 0.33654914, -0.49120612, -1.6068762…\n$ Posttest_Score        &lt;dbl&gt; -1.34709242, 1.43972775, -0.78972839, -2.4618204…\n$ Baseline_Confidence   &lt;dbl&gt; -0.37485943, 0.01220473, 0.39926888, -2.18115882…\n$ Posttest_Confidence   &lt;dbl&gt; 0.23891063, 0.53917812, 0.53917812, -3.36429935,…\n$ Baseline_Anxiety      &lt;dbl&gt; 2.49202355, -0.85159304, -0.57295832, 1.65611940…\n$ Posttest_Anxiety      &lt;dbl&gt; 2.15254688, -0.25189270, -0.99809809, 2.40128201…\n$ Baseline_Difficulty   &lt;dbl&gt; 1.15470752, -1.16207408, -0.20810518, 2.24495769…\n$ Posttest_Difficulty   &lt;dbl&gt; 1.4257825, -0.7405502, -0.0184393, 2.4573694, 0.…\n$ Baseline_Test_Version &lt;chr&gt; \"B\", \"A\", \"B\", \"A\", \"B\", \"A\", \"A\", \"B\", \"A\", \"A\"…\n$ Posttest_Test_Version &lt;fct&gt; A, B, A, B, A, B, B, A, B, B, A, B, B, B, B, B, …\n$ Cohort_2              &lt;dbl&gt; -0.3469771, -0.3469771, -0.3469771, -0.3469771, …\n$ Cohort_3              &lt;dbl&gt; -0.9569993, -0.9569993, -0.9569993, -0.9569993, …\n\nShow/Hide Codedata_rq2 |&gt;\n  mutate(across(Baseline_Test_Version, factor)) |&gt;\n  purrr::discard(is.numeric) |&gt;\n  summary()\n\n Participant              Condition                  Gender        Cohort  \n Length:148         Control    :73   Men                :66   Cohort 1:61  \n Class :character   Mindfulness:75   Women or Non-binary:82   Cohort 2:16  \n Mode  :character                                             Cohort 3:71  \n Baseline_Test_Version Posttest_Test_Version\n A:75                  A:73                 \n B:73                  B:75                 \n                                            \n\nShow/Hide Codedata_rq2 |&gt;\n  get_summary_stats(show = c(\"min\", \"max\", \"mean\", \"sd\"))\n\n\n\n\nvariable\nn\nmin\nmax\nmean\nsd\n\n\n\nSemester_Week\n148\n-1.474\n1.755\n0.00\n1.000\n\n\nBaseline_Threat\n148\n-2.394\n2.201\n0.00\n1.000\n\n\nEMA_Threat\n148\n-2.230\n2.420\n0.00\n1.000\n\n\nBaseline_n_items\n148\n10.000\n10.000\n10.00\n0.000\n\n\nPosttest_n_items\n148\n11.000\n12.000\n11.98\n0.141\n\n\nBaseline_Score\n148\n-2.111\n3.511\n0.00\n1.000\n\n\nPosttest_Score\n148\n-2.462\n2.957\n0.00\n1.000\n\n\nBaseline_Confidence\n148\n-3.213\n2.206\n0.00\n1.000\n\n\nPosttest_Confidence\n148\n-3.464\n1.840\n0.00\n1.000\n\n\nBaseline_Anxiety\n148\n-2.152\n2.492\n0.00\n1.000\n\n\nPosttest_Anxiety\n148\n-1.993\n2.650\n0.00\n1.000\n\n\nBaseline_Difficulty\n148\n-2.389\n2.381\n0.00\n1.000\n\n\nPosttest_Difficulty\n148\n-2.701\n2.457\n0.00\n1.000\n\n\nCohort_2\n148\n-0.347\n2.863\n0.00\n1.000\n\n\nCohort_3\n148\n-0.957\n1.038\n0.00\n1.000",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data and Environment Setup</span>"
    ]
  },
  {
    "objectID": "chapters/06-variable-characteristics.html",
    "href": "chapters/06-variable-characteristics.html",
    "title": "\n6  Characteristics of Fixed Effects Variables for Mixed Models\n",
    "section": "",
    "text": "6.1 Dependent Variables\nThe following code reproduces the factor coding and descriptive statistics reported in Table 3 of the main text.",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Characteristics of Fixed Effects Variables for Mixed Models</span>"
    ]
  },
  {
    "objectID": "chapters/06-variable-characteristics.html#dependent-variables",
    "href": "chapters/06-variable-characteristics.html#dependent-variables",
    "title": "\n6  Characteristics of Fixed Effects Variables for Mixed Models\n",
    "section": "",
    "text": "Show/Hide Codefor (p in str_perception_levels) {\n  cat(paste0(\"#### \", p, \"\\n\\n\"))\n\n  df &lt;- data_rq1 %&gt;%\n    filter(perception == p) %&gt;%\n    group_by(Timepoint) %&gt;%\n    get_summary_stats(rating, type = \"common\") %&gt;%\n    mutate(across(c(mean, sd), ~ scales::number(.x, accuracy = .01)))\n\n  print(kable(df))\n\n  cat(\"\\n\")\n\n  rm(p, df)\n}\nConfidence\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTimepoint\nvariable\nn\nmin\nmax\nmedian\niqr\nmean\nsd\nse\nci\n\n\n\nBaseline\nrating\n1490\n1\n6\n4\n2\n3.69\n1.44\n0.037\n0.073\n\n\nPosttest\nrating\n1785\n1\n6\n4\n2\n3.88\n1.46\n0.035\n0.068\n\n\nAnxiety\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTimepoint\nvariable\nn\nmin\nmax\nmedian\niqr\nmean\nsd\nse\nci\n\n\n\nBaseline\nrating\n1490\n1\n6\n3\n2\n3.31\n1.41\n0.036\n0.071\n\n\nPosttest\nrating\n1785\n1\n6\n3\n2\n3.00\n1.37\n0.033\n0.064\n\n\nDifficulty\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTimepoint\nvariable\nn\nmin\nmax\nmedian\niqr\nmean\nsd\nse\nci\n\n\n\nBaseline\nrating\n1490\n1\n6\n4\n1\n3.55\n1.26\n0.033\n0.064\n\n\nPosttest\nrating\n1785\n1\n6\n4\n2\n3.43\n1.30\n0.031\n0.060",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Characteristics of Fixed Effects Variables for Mixed Models</span>"
    ]
  },
  {
    "objectID": "chapters/06-variable-characteristics.html#covariates",
    "href": "chapters/06-variable-characteristics.html#covariates",
    "title": "\n6  Characteristics of Fixed Effects Variables for Mixed Models\n",
    "section": "\n6.2 Covariates",
    "text": "6.2 Covariates\nCohort\n\nShow/Hide Codedata_rq1$Cohort %&gt;%\n  contrasts() %&gt;%\n  as_tibble(rownames = \"Factor Levels\") %&gt;%\n  round_all_doubles()\n\n\n\n\nFactor Levels\nCohort 2\nCohort 3\n\n\n\nCohort 1\n-0.11\n-0.48\n\n\nCohort 2\n0.89\n-0.48\n\n\nCohort 3\n-0.11\n0.52\n\n\n\n\n\n\nSemester Week\n\nShow/Hide Codedata_rq1 %&gt;%\n  select(Participant, Semester_Week) %&gt;%\n  unique() %&gt;%\n  get_summary_stats(Semester_Week, type = \"common\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nn\nmin\nmax\nmedian\niqr\nmean\nsd\nse\nci\n\n\nSemester_Week\n149\n-4.087\n4.913\n-1.087\n5\n0\n2.79\n0.229\n0.452\n\n\n\n\n\nTest Version\n\nShow/Hide Codedata_rq1$Test_Version %&gt;%\n  contrasts() %&gt;%\n  as_tibble(rownames = \"Factor Levels\") %&gt;%\n  round_all_doubles()\n\n\n\n\nFactor Levels\nB\n\n\n\nA\n-0.50\n\n\nB\n0.50\n\n\n\n\n\n\nItem-Level Accuracy\nFactor Coding:\n\nShow/Hide Codedata_rq1$`Item-Level Accuracy` %&gt;%\n  contrasts() %&gt;%\n  as_tibble(rownames = \"Factor Levels\") %&gt;%\n  round_all_doubles()\n\n\n\n\nFactor Levels\nCorrect\n\n\n\nIncorrect\n-0.44\n\n\nCorrect\n0.56\n\n\n\n\n\n\nBaseline and Posttest Means and Standard Deviations:\n\nShow/Hide Codedata_rq1 %&gt;%\n  select(Participant, Timepoint, Item, Accuracy_Raw) %&gt;%\n  unique() %&gt;%\n  group_by(Timepoint) %&gt;%\n  get_summary_stats(type = \"common\") %&gt;%\n  mutate(across(c(mean, sd), ~ scales::number(.x, accuracy = .01)))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTimepoint\nvariable\nn\nmin\nmax\nmedian\niqr\nmean\nsd\nse\nci\n\n\n\nBaseline\nAccuracy_Raw\n1490\n0\n1\n0\n1\n0.43\n0.50\n0.013\n0.025\n\n\nPosttest\nAccuracy_Raw\n1785\n0\n1\n0\n1\n0.44\n0.50\n0.012\n0.023\n\n\n\n\n\n\nBaseline Threat\n\nShow/Hide Codedata_rq1 %&gt;%\n  select(Participant, Baseline_Threat) %&gt;%\n  unique() %&gt;%\n  get_summary_stats(Baseline_Threat, type = \"common\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nn\nmin\nmax\nmedian\niqr\nmean\nsd\nse\nci\n\n\nBaseline_Threat\n149\n-3.102\n2.865\n-0.035\n1.933\n0\n1.297\n0.106\n0.21",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Characteristics of Fixed Effects Variables for Mixed Models</span>"
    ]
  },
  {
    "objectID": "chapters/06-variable-characteristics.html#main-independent-variables-of-interest",
    "href": "chapters/06-variable-characteristics.html#main-independent-variables-of-interest",
    "title": "\n6  Characteristics of Fixed Effects Variables for Mixed Models\n",
    "section": "\n6.3 Main Independent Variables of Interest",
    "text": "6.3 Main Independent Variables of Interest\nTimepoint\n\nShow/Hide Codedata_rq1$Timepoint %&gt;%\n  contrasts() %&gt;%\n  as_tibble(rownames = \"Factor Levels\")\n\n\n\n\nFactor Levels\nPosttest\n\n\n\nBaseline\n0\n\n\nPosttest\n1\n\n\n\n\n\n\nCondition\n\nShow/Hide Codedata_rq1$Condition %&gt;%\n  contrasts() %&gt;%\n  as_tibble(rownames = \"Factor Levels\")\n\n\n\n\nFactor Levels\nMindfulness\n\n\n\nControl\n-0.5\n\n\nMindfulness\n0.5\n\n\n\n\n\n\nGender\n\nShow/Hide Codedata_rq1$Gender %&gt;%\n  contrasts() %&gt;%\n  as_tibble(rownames = \"Factor Levels\") %&gt;%\n  round_all_doubles()\n\n\n\n\nFactor Levels\nWomen or Non-binary\n\n\n\nMen\n-0.56\n\n\nWomen or Non-binary\n0.44",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Characteristics of Fixed Effects Variables for Mixed Models</span>"
    ]
  },
  {
    "objectID": "chapters/07-baseline-correlations.html",
    "href": "chapters/07-baseline-correlations.html",
    "title": "\n7  Correlations of Variables at Baseline\n",
    "section": "",
    "text": "7.1 Reproduction of Figure 3\nShow/Hide Codedata_rq1 %&gt;%\n  filter(Timepoint == \"Baseline\") %&gt;%\n  group_by(Participant, perception, Baseline_Threat) %&gt;%\n  summarise(rating = mean(rating), Score = mean(Score)) %&gt;%\n  pivot_wider(\n    names_from = perception,\n    values_from = rating\n  ) %&gt;%\n  GGally::ggpairs(\n    columns = c(\n      \"Confidence\",\n      \"Anxiety\",\n      \"Difficulty\",\n      \"Baseline_Threat\",\n      \"Score\"\n    ),\n    columnLabels = c(\n      \"Confidence\",\n      \"Anxiety\",\n      \"Difficulty\",\n      \"Psych. Threat\",\n      \"Score\"\n    ),\n    diag = list(continuous = fun_diag),\n    upper = list(continuous = wrap(fun_cor_stat, method = \"pearson\", size = 6)),\n    lower = list(continuous = fun_lower)\n  ) +\n  theme(panel.spacing = unit(3, \"mm\"), axis.text = element_text(size = 9)) +\n  scale_x_continuous(labels = ~ round(., 1)) +\n  scale_y_continuous(labels = ~ round(., 1))\n\n\n\nSupplementary Figure 7.1: Correlations and Variable Distributions at Baseline (Main Text, Figure 3)",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Correlations of Variables at Baseline</span>"
    ]
  },
  {
    "objectID": "chapters/07-baseline-correlations.html#association-between-item-level-judgments-by-task",
    "href": "chapters/07-baseline-correlations.html#association-between-item-level-judgments-by-task",
    "title": "\n7  Correlations of Variables at Baseline\n",
    "section": "\n7.2 Association Between Item-Level Judgments by Task",
    "text": "7.2 Association Between Item-Level Judgments by Task\n\nShow/Hide Codebaseline_task_compare &lt;- data_rq1 %&gt;%\n  filter(Timepoint == \"Baseline\") %&gt;%\n  group_by(perception) %&gt;%\n  nest %&gt;%\n  mutate(\n    data = map(\n      data,\n      ~ group_by(.x, Participant, Part) %&gt;%\n        summarise(rating = mean(rating), .groups = \"drop\") %&gt;%\n        ungroup\n    ),\n    t_test = map(\n      data,\n      ~ pairwise_t_test(\n        .x,\n        rating ~ Part,\n        p.adjust.method = \"BH\",\n        paired = TRUE\n      )\n    ),\n    cohens = map(data, ~ cohens_d(.x, rating ~ Part, paired = TRUE)),\n    tmp = map2(\n      t_test,\n      cohens,\n      ~ full_join(.x, .y, by = join_by(.y., group1, group2, n1, n2))\n    )\n  ) %&gt;%\n  name_list_columns() %&gt;%\n  unnest(tmp) %&gt;%\n  select(-c(data:`.y.`))\n\nbaseline_task_accuracy &lt;- data_rq1 |&gt;\n  filter(Timepoint == \"Baseline\") |&gt;\n  pivot_wider(\n    names_from = perception,\n    values_from = rating\n  ) |&gt;\n  summarise(\n    .by = Part,\n    Score = mean(Score)\n  ) |&gt;\n  deframe() |&gt;\n  scales::number(accuracy = .01)\n\n# Stats to be used below:\nquant_d &lt;- baseline_task_compare |&gt;\n  filter(group2 == \"Quantitative\") |&gt;\n  ungroup() |&gt;\n  mutate(across(effsize, \\(x) round(abs(x), 2))) |&gt;\n  get_summary_stats(effsize, show = c(\"min\", \"max\"))\n\ncompare_23 &lt;- baseline_task_compare |&gt;\n  filter(str_detect(group1, \"Cat\"), str_detect(group2, \"Qual\")) |&gt;\n  select(perception, effsize) |&gt;\n  deframe() |&gt;\n  round(2) |&gt;\n  abs()\n\n\n\nShow/Hide Codedodge_width &lt;- .7\n\ndata_rq1 %&gt;%\n  filter(Timepoint == \"Baseline\") %&gt;%\n  group_by(Participant, Part, perception) %&gt;%\n  summarise(rating = mean(rating), .groups = \"drop\") %&gt;%\n  mutate(\n    perception = factor(\n      perception,\n      levels = c(\"Confidence\", \"Anxiety\", \"Difficulty\")\n    ),\n    Part = fct_relevel(Part, \"Quantitative\")\n  ) %&gt;%\n  ggplot(aes(Part, rating, group = Part, color = Part)) +\n  geom_point(\n    position = position_jitterdodge(\n      jitter.width = 1,\n      jitter.height = .2,\n      dodge.width = .7\n    ),\n    alpha = .5,\n    size = .8\n  ) +\n  stat_summary(\n    geom = \"crossbar\",\n    fun.data = \"mean_cl_boot\",\n    color = \"black\",\n    width = .3,\n    linewidth = .5,\n    fill = \"white\",\n    alpha = .3,\n    position = position_dodge(dodge_width)\n  ) +\n  ggpubr::geom_bracket(\n    aes(\n      xmin = group1,\n      xmax = group2,\n      label = round(abs(effsize), 2) %&gt;% paste(\"d =\", .)\n    ),\n    data = baseline_task_compare,\n    y.position = rep(seq(6.5, 8, .6), 3),\n    inherit.aes = FALSE,\n    label.size = 3\n  ) +\n  facet_grid(~perception) +\n  theme(\n    legend.position = \"none\",\n    axis.text.x = element_text(\n      angle = 0,\n      hjust = .5,\n      vjust = 1,\n      size = 10\n    ),\n    text = element_text(size = 15)\n  ) +\n  labs(x = NULL, y = \"Mean Item Rating at Baseline\") +\n  scale_y_continuous(breaks = 1:6, limits = c(0.5, 8)) +\n  scale_x_discrete(\n    labels = ~ paste0(\n      paste(\"Part\", 1:3),\n      \"\\n(\",\n      baseline_task_accuracy[.x],\n      \")\"\n    )\n  )\n\n\n\nSupplementary Figure 7.2: Mean Judgments by Physics Task Type at Baseline\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSupplementary Figure 7.2: Cohen’s d values for paired samples were obtained by calculating a mean perception rating for each participant by task and perception type and then dividing the mean difference by the standard deviation of the difference for each comparison. Crossbars show means and bootstrapped 95% confidence intervals. Mean accuracy for each task is shown in parentheses along the x axis.\n\n\nPerception ratings were sensitive to fluctuations in performance between the physics tasks, indicating construct validity (see Supplementary Figure 7.2). For example, there was a large effect size difference in perceptions of confidence, anxiety, and difficulty between ratings on the quantitative problem solving item compared to mean ratings on both the problem categorization items and the qualitative problem solving items (Cohen’s d = 1.04 - 1.75). These differences make sense given that students performed near floor on the quantitative problem, and considerably better on the other two tasks. There was a small effect size difference between confidence ratings on the problem categorization items compared to the qualitative items (Cohen’s d = 0.22), with greater confidence reported on the problem categorization items. A likely explanation is that some of the categorization items were designed to appear simpler than they are in reality, so students may have been overconfident on those items. The difference between anxiety and difficulty ratings on the problem categorization items compared to the qualitative items was marginal (Cohen’s d = 0.12, 0.08). Overall, students’ perceptions varied with mean accuracy on the different types of items.",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Correlations of Variables at Baseline</span>"
    ]
  },
  {
    "objectID": "chapters/08-research-question-1.html",
    "href": "chapters/08-research-question-1.html",
    "title": "\n8  Research Question 1\n",
    "section": "",
    "text": "8.1 Model Specification\nShow/Hide Codemodels_rq1 &lt;- data_rq1 %&gt;%\n  group_by(perception) %&gt;%\n  nest %&gt;%\n  mutate(\n    # Models with all covariates included\n    mod_full = map(\n      data,\n      ~ lmer(\n        rating ~\n          Cohort +\n            Semester_Week +\n            Test_Version +\n            `Item-Level Accuracy` +\n            Baseline_Threat +\n            Gender +\n            Timepoint * Condition +\n            (1 | Participant) +\n            (1 | Item),\n        data = .x\n      )\n    ),\n    # Models with no covariates\n    mod_cov_removed = map(\n      data,\n      ~ lmer(\n        rating ~\n          Cohort +\n            Semester_Week +\n            Test_Version +\n            Gender +\n            Timepoint * Condition +\n            (1 | Participant) +\n            (1 | Item),\n        data = .x\n      )\n    ),\n    # Models with gender interaction\n    mod_gender_interact = map(\n      data,\n      ~ lmer(\n        rating ~\n          Cohort +\n            Semester_Week +\n            Test_Version +\n            `Item-Level Accuracy` +\n            Baseline_Threat +\n            Timepoint * Condition * Gender +\n            (1 | Participant) +\n            (1 | Item),\n        data = .x\n      )\n    ),\n    # Empty means models (only random effects)\n    mod_empty_means = map(\n      data,\n      ~ lmer(\n        rating ~\n          (1 | Participant) +\n            (1 | Item),\n        data = .x\n      )\n    ),\n    # Compare 2-way and 3-way interaction models\n    comparison = pmap(list(mod_full, mod_gender_interact), anova)\n  ) %&gt;%\n  name_list_columns() # Name the list columns\n\n# Data with model-predicted outcome values\npredicted_values &lt;- data_rq1 %&gt;%\n  group_by(perception) %&gt;%\n  nest() %&gt;%\n  mutate(\n    predicted = case_match(\n      perception,\n      \"Confidence\" ~\n        map(\n          data,\n          ~ predict(\n            models_rq1$mod_gender_interact$Confidence,\n            newdata = .x,\n            se.fit = TRUE\n          ) %&gt;%\n            as_tibble()\n        ),\n      \"Anxiety\" ~\n        map(\n          data,\n          ~ predict(\n            models_rq1$mod_gender_interact$Anxiety,\n            newdata = .x,\n            se.fit = TRUE\n          ) %&gt;%\n            as_tibble()\n        ),\n      \"Difficulty\" ~\n        map(\n          data,\n          ~ predict(\n            models_rq1$mod_full$Difficulty,\n            newdata = .x,\n            se.fit = TRUE\n          ) %&gt;%\n            as_tibble()\n        )\n    )\n  ) %&gt;%\n  unnest(c(data, predicted))",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Research Question 1</span>"
    ]
  },
  {
    "objectID": "chapters/08-research-question-1.html#reproduction-of-table-4",
    "href": "chapters/08-research-question-1.html#reproduction-of-table-4",
    "title": "\n8  Research Question 1\n",
    "section": "\n8.2 Reproduction of Table 4",
    "text": "8.2 Reproduction of Table 4\n\nShow/Hide Codehandle_model_print(\n  list(\n    models_rq1$mod_gender_interact$Confidence,\n    models_rq1$mod_gender_interact$Anxiety,\n    models_rq1$mod_full$Difficulty\n  ),\n  str_perception_levels |&gt;\n    (\\(x) paste0(\"H\", 1:3, \": \", x))(),\n  n_models = 3,\n  is_lmer = TRUE,\n  raneff_rownum = 15\n)\n\n\nSupplementary Table 8.1: Results from Mixed Effects Models Testing Hypotheses 1-3: Effects of Mindfulness Training on Item-Level Judgments While Answering Physics Questions\n\n\n\n\n \nH1: Confidence\nH2: Anxiety\nH3: Difficulty\n\n\nPredictors\nEstimates\nSE\np\nEstimates\nSE\np\nEstimates\nSE\np\n\n\n(Intercept)\n3.69\n0.15\n&lt;0.001\n3.33\n0.12\n&lt;0.001\n3.56\n0.12\n&lt;0.001\n\n\nCohort [Cohort 2]\n0.38\n0.31\n0.222\n-0.16\n0.43\n0.709\n-0.52\n0.32\n0.106\n\n\nCohort [Cohort 3]\n0.07\n0.27\n0.785\n0.06\n0.38\n0.868\n-0.33\n0.28\n0.235\n\n\nSemester Week\n0.10\n0.05\n0.036\n-0.04\n0.07\n0.537\n-0.12\n0.05\n0.019\n\n\nTest Version [B]\n-0.13\n0.12\n0.268\n-0.08\n0.10\n0.385\n-0.07\n0.10\n0.518\n\n\nItem-Level Accuracy [Correct]\n0.13\n0.04\n0.005\n-0.08\n0.04\n0.026\n-0.03\n0.04\n0.426\n\n\nBaseline Threat\n-0.24\n0.04\n&lt;0.001\n0.22\n0.06\n&lt;0.001\n0.15\n0.04\n&lt;0.001\n\n\nTimepoint [Posttest]\n0.19\n0.04\n&lt;0.001\n-0.34\n0.03\n&lt;0.001\n-0.12\n0.04\n&lt;0.001\n\n\nCondition [Mindfulness]\n0.07\n0.11\n0.545\n-0.25\n0.15\n0.087\n-0.08\n0.11\n0.479\n\n\nGender [Women or Non-binary]\n-0.35\n0.12\n0.003\n0.49\n0.16\n0.002\n0.22\n0.11\n0.048\n\n\nTimepoint [Posttest] × Condition [Mindfulness]\n0.13\n0.08\n0.089\n-0.11\n0.07\n0.102\n-0.29\n0.07\n&lt;0.001\n\n\nTimepoint [Posttest] × Gender [Women or Non-binary]\n0.06\n0.08\n0.451\n-0.12\n0.07\n0.071\n\n\n\n\n\nCondition [Mindfulness] × Gender [Women or Non-binary]\n-0.19\n0.22\n0.391\n-0.11\n0.30\n0.721\n\n\n\n\n\n(Timepoint [Posttest] × Condition [Mindfulness]) × Gender [Women or Non-binary]\n0.32\n0.15\n0.034\n-0.31\n0.13\n0.018\n\n\n\n\n\nRandom Effects\n\n\nσ2\n\n1.17\n0.87\n0.93\n\n\nτ00\n\n0.33 Participant\n\n0.72 Participant\n\n0.37 Participant\n\n\n\n\n\n0.45 Item\n\n0.17 Item\n\n0.27 Item\n\n\n\n\nICC\n0.40\n0.51\n0.41\n\n\n\nN\n149 Participant\n\n149 Participant\n\n149 Participant\n\n\n\n\n\n22 Item\n\n22 Item\n\n22 Item\n\n\n\nObservations\n3275\n3275\n3275\n\n\nMarginal R2 / Conditional R2\n\n0.099 / 0.461\n0.123 / 0.567\n0.068 / 0.448",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Research Question 1</span>"
    ]
  },
  {
    "objectID": "chapters/08-research-question-1.html#confidence-judgments-model-comparison",
    "href": "chapters/08-research-question-1.html#confidence-judgments-model-comparison",
    "title": "\n8  Research Question 1\n",
    "section": "\n8.3 Confidence Judgments: Model Comparison",
    "text": "8.3 Confidence Judgments: Model Comparison\n\nShow/Hide Codehandle_model_print(\n  list(\n    models_rq1$mod_cov_removed$Confidence,\n    models_rq1$mod_full$Confidence,\n    models_rq1$mod_gender_interact$Confidence\n  ),\n  c(\n    \"Accuracy and Baseline Threat Removed\",\n    \"2-Way Interaction\",\n    \"3-Way Interaction\"\n  ),\n  n_models = 3,\n  is_lmer = TRUE,\n  raneff_rownum = 15\n)\n\n\nSupplementary Table 8.2: Comparison of Models Predicting Confidence Judgments\n\n\n\n\n \nAccuracy and Baseline Threat Removed\n2-Way Interaction\n3-Way Interaction\n\n\nPredictors\nEstimates\nSE\np\nEstimates\nSE\np\nEstimates\nSE\np\n\n\n(Intercept)\n3.69\n0.16\n&lt;0.001\n3.69\n0.15\n&lt;0.001\n3.69\n0.15\n&lt;0.001\n\n\nCohort [Cohort 2]\n0.28\n0.34\n0.409\n0.38\n0.31\n0.221\n0.38\n0.31\n0.222\n\n\nCohort [Cohort 3]\n0.01\n0.30\n0.977\n0.07\n0.27\n0.786\n0.07\n0.27\n0.785\n\n\nSemester Week\n0.09\n0.05\n0.082\n0.10\n0.05\n0.035\n0.10\n0.05\n0.036\n\n\nTest Version [B]\n-0.14\n0.12\n0.235\n-0.14\n0.12\n0.253\n-0.13\n0.12\n0.268\n\n\nGender [Women or Non-binary]\n-0.51\n0.12\n&lt;0.001\n-0.32\n0.11\n0.003\n-0.35\n0.12\n0.003\n\n\nTimepoint [Posttest]\n0.19\n0.04\n&lt;0.001\n0.19\n0.04\n&lt;0.001\n0.19\n0.04\n&lt;0.001\n\n\nCondition [Mindfulness]\n0.10\n0.12\n0.394\n0.07\n0.11\n0.543\n0.07\n0.11\n0.545\n\n\nTimepoint [Posttest] × Condition [Mindfulness]\n0.13\n0.08\n0.086\n0.13\n0.08\n0.090\n0.13\n0.08\n0.089\n\n\nItem-Level Accuracy [Correct]\n\n\n\n0.12\n0.04\n0.005\n0.13\n0.04\n0.005\n\n\nBaseline Threat\n\n\n\n-0.24\n0.04\n&lt;0.001\n-0.24\n0.04\n&lt;0.001\n\n\nTimepoint [Posttest] × Gender [Women or Non-binary]\n\n\n\n\n\n\n0.06\n0.08\n0.451\n\n\nCondition [Mindfulness] × Gender [Women or Non-binary]\n\n\n\n\n\n\n-0.19\n0.22\n0.391\n\n\n(Timepoint [Posttest] × Condition [Mindfulness]) × Gender [Women or Non-binary]\n\n\n\n\n\n\n0.32\n0.15\n0.034\n\n\nRandom Effects\n\n\nσ2\n\n1.17\n1.17\n1.17\n\n\nτ00\n\n0.42 Participant\n\n0.33 Participant\n\n0.33 Participant\n\n\n\n\n\n0.46 Item\n\n0.45 Item\n\n0.45 Item\n\n\n\n\nICC\n0.43\n0.40\n0.40\n\n\n\nN\n149 Participant\n\n149 Participant\n\n149 Participant\n\n\n\n\n\n22 Item\n\n22 Item\n\n22 Item\n\n\n\nObservations\n3275\n3275\n3275\n\n\nMarginal R2 / Conditional R2\n\n0.057 / 0.463\n0.099 / 0.460\n0.099 / 0.461",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Research Question 1</span>"
    ]
  },
  {
    "objectID": "chapters/08-research-question-1.html#anxiety-judgments-model-comparison",
    "href": "chapters/08-research-question-1.html#anxiety-judgments-model-comparison",
    "title": "\n8  Research Question 1\n",
    "section": "\n8.4 Anxiety Judgments: Model Comparison",
    "text": "8.4 Anxiety Judgments: Model Comparison\n\nShow/Hide Codehandle_model_print(\n  list(\n    models_rq1$mod_cov_removed$Anxiety,\n    models_rq1$mod_full$Anxiety,\n    models_rq1$mod_gender_interact$Anxiety\n  ),\n  c(\n    \"Accuracy and Baseline Threat Removed\",\n    \"2-Way Interaction\",\n    \"3-Way Interaction\"\n  ),\n  n_models = 3,\n  is_lmer = TRUE,\n  raneff_rownum = 15\n)\n\n\nSupplementary Table 8.3: Comparison of Models Predicting Anxiety Judgments\n\n\n\n\n \nAccuracy and Baseline Threat Removed\n2-Way Interaction\n3-Way Interaction\n\n\nPredictors\nEstimates\nSE\np\nEstimates\nSE\np\nEstimates\nSE\np\n\n\n(Intercept)\n3.33\n0.12\n&lt;0.001\n3.33\n0.12\n&lt;0.001\n3.33\n0.12\n&lt;0.001\n\n\nCohort [Cohort 2]\n-0.08\n0.45\n0.867\n-0.16\n0.43\n0.703\n-0.16\n0.43\n0.709\n\n\nCohort [Cohort 3]\n0.12\n0.40\n0.764\n0.06\n0.38\n0.879\n0.06\n0.38\n0.868\n\n\nSemester Week\n-0.03\n0.07\n0.639\n-0.04\n0.07\n0.538\n-0.04\n0.07\n0.537\n\n\nTest Version [B]\n-0.08\n0.10\n0.408\n-0.08\n0.10\n0.399\n-0.08\n0.10\n0.385\n\n\nGender [Women or Non-binary]\n0.60\n0.16\n&lt;0.001\n0.42\n0.15\n0.006\n0.49\n0.16\n0.002\n\n\nTimepoint [Posttest]\n-0.34\n0.03\n&lt;0.001\n-0.34\n0.03\n&lt;0.001\n-0.34\n0.03\n&lt;0.001\n\n\nCondition [Mindfulness]\n-0.29\n0.15\n0.063\n-0.25\n0.15\n0.087\n-0.25\n0.15\n0.087\n\n\nTimepoint [Posttest] × Condition [Mindfulness]\n-0.11\n0.07\n0.102\n-0.11\n0.07\n0.105\n-0.11\n0.07\n0.102\n\n\nItem-Level Accuracy [Correct]\n\n\n\n-0.08\n0.04\n0.028\n-0.08\n0.04\n0.026\n\n\nBaseline Threat\n\n\n\n0.23\n0.06\n&lt;0.001\n0.22\n0.06\n&lt;0.001\n\n\nTimepoint [Posttest] × Gender [Women or Non-binary]\n\n\n\n\n\n\n-0.12\n0.07\n0.071\n\n\nCondition [Mindfulness] × Gender [Women or Non-binary]\n\n\n\n\n\n\n-0.11\n0.30\n0.721\n\n\n(Timepoint [Posttest] × Condition [Mindfulness]) × Gender [Women or Non-binary]\n\n\n\n\n\n\n-0.31\n0.13\n0.018\n\n\nRandom Effects\n\n\nσ2\n\n0.87\n0.87\n0.87\n\n\nτ00\n\n0.80 Participant\n\n0.72 Participant\n\n0.72 Participant\n\n\n\n\n\n0.18 Item\n\n0.17 Item\n\n0.17 Item\n\n\n\n\nICC\n0.53\n0.51\n0.51\n\n\n\nN\n149 Participant\n\n149 Participant\n\n149 Participant\n\n\n\n\n\n22 Item\n\n22 Item\n\n22 Item\n\n\n\nObservations\n3275\n3275\n3275\n\n\nMarginal R2 / Conditional R2\n\n0.078 / 0.565\n0.120 / 0.565\n0.123 / 0.567",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Research Question 1</span>"
    ]
  },
  {
    "objectID": "chapters/08-research-question-1.html#difficulty-judgments-model-comparison",
    "href": "chapters/08-research-question-1.html#difficulty-judgments-model-comparison",
    "title": "\n8  Research Question 1\n",
    "section": "\n8.5 Difficulty Judgments: Model Comparison",
    "text": "8.5 Difficulty Judgments: Model Comparison\n\nShow/Hide Codehandle_model_print(\n  list(\n    models_rq1$mod_cov_removed$Difficulty,\n    models_rq1$mod_full$Difficulty,\n    models_rq1$mod_gender_interact$Difficulty\n  ),\n  c(\n    \"Accuracy and Baseline Threat Removed\",\n    \"2-Way Interaction\",\n    \"3-Way Interaction\"\n  ),\n  n_models = 3,\n  is_lmer = TRUE,\n  raneff_rownum = 15\n)\n\n\nSupplementary Table 8.4: Comparison of Models Predicting Difficulty Judgments\n\n\n\n\n \nAccuracy and Baseline Threat Removed\n2-Way Interaction\n3-Way Interaction\n\n\nPredictors\nEstimates\nSE\np\nEstimates\nSE\np\nEstimates\nSE\np\n\n\n(Intercept)\n3.56\n0.13\n&lt;0.001\n3.56\n0.12\n&lt;0.001\n3.56\n0.12\n&lt;0.001\n\n\nCohort [Cohort 2]\n-0.46\n0.33\n0.166\n-0.52\n0.32\n0.106\n-0.52\n0.32\n0.107\n\n\nCohort [Cohort 3]\n-0.29\n0.29\n0.315\n-0.33\n0.28\n0.235\n-0.33\n0.28\n0.234\n\n\nSemester Week\n-0.11\n0.05\n0.032\n-0.12\n0.05\n0.019\n-0.12\n0.05\n0.019\n\n\nTest Version [B]\n-0.07\n0.10\n0.528\n-0.07\n0.10\n0.518\n-0.07\n0.10\n0.507\n\n\nGender [Women or Non-binary]\n0.34\n0.11\n0.003\n0.22\n0.11\n0.048\n0.16\n0.12\n0.196\n\n\nTimepoint [Posttest]\n-0.12\n0.04\n&lt;0.001\n-0.12\n0.04\n&lt;0.001\n-0.12\n0.04\n&lt;0.001\n\n\nCondition [Mindfulness]\n-0.10\n0.12\n0.376\n-0.08\n0.11\n0.479\n-0.08\n0.11\n0.478\n\n\nTimepoint [Posttest] × Condition [Mindfulness]\n-0.29\n0.07\n&lt;0.001\n-0.29\n0.07\n&lt;0.001\n-0.29\n0.07\n&lt;0.001\n\n\nItem-Level Accuracy [Correct]\n\n\n\n-0.03\n0.04\n0.426\n-0.03\n0.04\n0.436\n\n\nBaseline Threat\n\n\n\n0.15\n0.04\n&lt;0.001\n0.15\n0.04\n&lt;0.001\n\n\nTimepoint [Posttest] × Gender [Women or Non-binary]\n\n\n\n\n\n\n0.12\n0.07\n0.076\n\n\nCondition [Mindfulness] × Gender [Women or Non-binary]\n\n\n\n\n\n\n0.03\n0.23\n0.910\n\n\n(Timepoint [Posttest] × Condition [Mindfulness]) × Gender [Women or Non-binary]\n\n\n\n\n\n\n0.11\n0.14\n0.420\n\n\nRandom Effects\n\n\nσ2\n\n0.93\n0.93\n0.93\n\n\nτ00\n\n0.41 Participant\n\n0.37 Participant\n\n0.38 Participant\n\n\n\n\n\n0.27 Item\n\n0.27 Item\n\n0.27 Item\n\n\n\n\nICC\n0.42\n0.41\n0.41\n\n\n\nN\n149 Participant\n\n149 Participant\n\n149 Participant\n\n\n\n\n\n22 Item\n\n22 Item\n\n22 Item\n\n\n\nObservations\n3275\n3275\n3275\n\n\nMarginal R2 / Conditional R2\n\n0.046 / 0.448\n0.068 / 0.448\n0.068 / 0.449",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Research Question 1</span>"
    ]
  },
  {
    "objectID": "chapters/08-research-question-1.html#reproduction-of-figure-4",
    "href": "chapters/08-research-question-1.html#reproduction-of-figure-4",
    "title": "\n8  Research Question 1\n",
    "section": "\n8.6 Reproduction of Figure 4",
    "text": "8.6 Reproduction of Figure 4\n\nShow/Hide Codedata_rq1 %&gt;%\n  group_by(Participant, Gender, perception, Timepoint, Condition) %&gt;%\n  summarise(rating = mean(rating), .groups = \"drop\") %&gt;%\n  mutate(\n    perception = factor(\n      perception,\n      levels = c(\"Confidence\", \"Anxiety\", \"Difficulty\")\n    )\n  ) %&gt;%\n  ggplot(aes(Timepoint, rating, group = Condition, color = Condition)) +\n  facet_grid(perception ~ Gender, margins = \"Gender\") +\n  stat_summary(geom = \"line\", fun = \"mean\") +\n  stat_summary(geom = \"errorbar\", fun.data = \"mean_se\", width = .2) +\n  stat_summary(geom = \"point\", fun = \"mean\") +\n  scale_y_continuous(breaks = 1:6, limits = c(1, 6)) +\n  scale_x_discrete(expand = expansion(mult = .3)) +\n  scale_color_manual(values = c(color_cntrl, color_mindful)) +\n  labs(x = NULL, y = \"Mean Rating (Raw Data)\") +\n  theme(\n    legend.position = \"right\",\n    plot.background = element_rect(fill = 'transparent'),\n    # aspect.ratio = 1,\n    legend.background = element_rect(fill = 'transparent'),\n    legend.key = element_rect(\n      fill = 'white',\n      linewidth = .2,\n      linetype = 'solid',\n      color = color_cntrl\n    )\n  )\n\n\n\nSupplementary Figure 8.1: Participants’ Mean Judgment Ratings at Baseline and Posttest by Experimental Condition and Gender",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Research Question 1</span>"
    ]
  },
  {
    "objectID": "chapters/08-research-question-1.html#reproduction-of-figure-5",
    "href": "chapters/08-research-question-1.html#reproduction-of-figure-5",
    "title": "\n8  Research Question 1\n",
    "section": "\n8.7 Reproduction of Figure 5",
    "text": "8.7 Reproduction of Figure 5\n\nShow/Hide Codepredicted_values %&gt;%\n  # Calculate the mean fit for each participant at baseline and posttest\n  group_by(Participant, perception, Gender, Condition, Timepoint) %&gt;%\n  summarise(fit = mean(fit), .groups = \"drop\") %&gt;%\n  # group by gender, condition and perform a paired t test with equal variance assumed\n  group_by(perception, Gender, Condition) %&gt;%\n  t_test(\n    formula = fit ~ Timepoint,\n    paired = TRUE,\n    var.equal = TRUE,\n    detailed = TRUE,\n    ref.group = \"Posttest\"\n  ) %&gt;%\n  # Convert 95% confidence intervals to SE\n  mutate(se = (conf.high - conf.low) / 3.92, .after = estimate) %&gt;%\n  # Reorder perception variables to match text\n  mutate(perception = fct_relevel(perception, \"Confidence\")) %&gt;%\n  ggplot(mapping = aes(x = Gender, y = estimate)) +\n  facet_wrap(~perception) +\n  labs(y = \"Estimated Change from Baseline to Posttest\") +\n  geom_col(\n    position = \"dodge\",\n    mapping = aes(fill = Condition)\n  ) +\n  geom_errorbar(\n    mapping = aes(ymin = conf.low, ymax = conf.high, group = Condition),\n    position = position_dodge(.9),\n    width = .2\n  ) +\n  geom_text(\n    mapping = aes(\n      label = round(estimate, 2),\n      y = ifelse(estimate &lt; 0, conf.low - .03, conf.high + .03),\n      group = Condition\n    ),\n    size = 3,\n    position = position_dodge(.9)\n  ) +\n  geom_hline(\n    yintercept = 0\n  ) +\n  scale_x_discrete(labels = c(\"Men\", \"Women/NB\")) +\n  scale_fill_manual(values = c(color_cntrl, color_mindful))\n\n\n\nSupplementary Figure 8.2: Estimated Marginal Means for Effects of Main Variables of Interest",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Research Question 1</span>"
    ]
  },
  {
    "objectID": "chapters/09-research-question-2.html",
    "href": "chapters/09-research-question-2.html",
    "title": "\n9  Research Question 2\n",
    "section": "",
    "text": "9.1 Model Specification\nMediation tests were conducted using mediation::mediate() using bias-corrected bootstrapped confidence intervals.\nShow/Hide Code# Formula for c path\n\nformula_t &lt;- function(perception) {\n  as.formula(\n    paste0(\n      \"Posttest_\",\n      perception,\n      \" ~\n          Condition * Gender +\n          Baseline_Score +\n          Cohort_2 +\n          Cohort_3 +\n          Semester_Week +\n          Posttest_Test_Version +\n          Baseline_Threat +\n          Baseline_\",\n      perception\n    )\n  )\n}\n\n# Formula for a path\n\nformula_m &lt;- function(perception) {\n  as.formula(\n    paste0(\n      \"EMA_Threat ~\n          Condition * Gender +\n          Baseline_Score +\n          Cohort_2 +\n          Cohort_3 +\n          Semester_Week +\n          Posttest_Test_Version +\n          Baseline_Threat +\n          Baseline_\",\n      perception\n    )\n  )\n}\n\n# Formula for c' and b paths\n\nformula_y &lt;- function(perception) {\n  as.formula(\n    paste0(\n      \"Posttest_\",\n      perception,\n      \" ~\n          Condition * Gender +\n          EMA_Threat * Gender +\n          Baseline_Score +\n          Cohort_2 +\n          Cohort_3 +\n          Semester_Week +\n          Posttest_Test_Version +\n          Baseline_Threat +\n          Baseline_\",\n      perception\n    )\n  )\n}\n\n# Function for removing gender moderations from paths\n# to show overall effects\nremove_interactions &lt;- function(perception, formula_fun) {\n  update.formula(\n    formula_fun(perception),\n    . ~ . - Condition:Gender - Gender:EMA_Threat\n  )\n}\n\n# Helper function to create lm with proper call\nlm_with_call &lt;- function(formula_func, perception, data, mod = TRUE) {\n  if (mod) {\n    formula &lt;- formula_func(perception)\n  } else {\n    formula &lt;- remove_interactions(perception, formula_func)\n  }\n  model &lt;- lm(formula, data = data)\n  model$call &lt;- call(\"lm\", formula = formula, data = quote(data))\n  return(model)\n}\n\n# Linear models with men coded as 0\nmodels_rq2_men &lt;- bind_rows(\n  list(\n    Confidence = data_rq2,\n    Anxiety = data_rq2,\n    Difficulty = data_rq2\n  ),\n  .id = \"perception\"\n) %&gt;%\n  nest(.by = \"perception\") %&gt;%\n  mutate(\n    mod_t = map2(data, perception, ~ lm_with_call(formula_t, .y, .x)),\n    mod_m = map2(data, perception, ~ lm_with_call(formula_m, .y, .x)),\n    mod_y = map2(data, perception, ~ lm_with_call(formula_y, .y, .x))\n  ) %&gt;%\n  group_by(perception) %&gt;%\n  name_list_columns()\n\n\n# Linear models with women and non-binary students coded as 0\nmodels_rq2_women &lt;- bind_rows(\n  list(\n    Confidence = data_rq2,\n    Anxiety = data_rq2,\n    Difficulty = data_rq2\n  ),\n  .id = \"perception\"\n) %&gt;%\n  # Reverse gender coding for women/nb path models\n  mutate(Gender = fct_relevel(Gender, \"Women or Non-binary\")) %&gt;%\n  nest(.by = \"perception\") %&gt;%\n  mutate(\n    mod_t = map2(data, perception, ~ lm_with_call(formula_t, .y, .x)),\n    mod_m = map2(data, perception, ~ lm_with_call(formula_m, .y, .x)),\n    mod_y = map2(data, perception, ~ lm_with_call(formula_y, .y, .x))\n  ) %&gt;%\n  group_by(perception) %&gt;%\n  name_list_columns()\n\n# Linear models without gender moderation\nmodels_rq2_no_mod &lt;- bind_rows(\n  list(\n    Confidence = data_rq2,\n    Anxiety = data_rq2,\n    Difficulty = data_rq2\n  ),\n  .id = \"perception\"\n) %&gt;%\n  nest(.by = \"perception\") %&gt;%\n  mutate(\n    mod_t = map2(\n      data,\n      perception,\n      ~ lm_with_call(formula_t, .y, .x, mod = FALSE)\n    ),\n    mod_m = map2(\n      data,\n      perception,\n      ~ lm_with_call(formula_m, .y, .x, mod = FALSE)\n    ),\n    mod_y = map2(\n      data,\n      perception,\n      ~ lm_with_call(formula_y, .y, .x, mod = FALSE)\n    )\n  ) %&gt;%\n  group_by(perception) %&gt;%\n  name_list_columns()\n\n# Function for printing model results\ntab_rq2_models &lt;- function(df, perception) {\n  lbl_out &lt;- paste0(\"Posttest \", perception)\n\n  handle_model_print(\n    mods &lt;- list(\n      df$mod_t[[perception]],\n      df$mod_m[[perception]],\n      df$mod_y[[perception]]\n    ),\n    nm = paste0(\n      \"Model \",\n      1:3,\n      \" DV:&lt;br&gt;\",\n      c(lbl_out, \"EMA Threat\", lbl_out)\n    ),\n    n_models = 3\n  )\n}\n\n# Function for printing path diagram\nplot_path_diagram &lt;- function(perception, gender) {\n  df &lt;- get(paste0(\"models_rq2_\", gender), envir = .GlobalEnv)\n\n  if (gender == \"no_mod\") {\n    dv &lt;- paste0(perception, \"\\n(Overall)\")\n  } else {\n    dv &lt;- paste0(perception, \"\\n(\", str_to_title(gender), \")\")\n  }\n\n  p &lt;- gg_path_diagram(\n    mod_t = df$mod_t[[perception]],\n    mod_m = df$mod_m[[perception]],\n    mod_y = df$mod_y[[perception]],\n    str_med = \"EMA_Threat\",\n    str_iv = \"ConditionMindfulness\",\n    lbl_med = \"EMA Threat\",\n    lbl_iv = \"Mindfulness\",\n    lbl_dv = dv,\n    pad_x = 3.5\n  )\n\n  return(p)\n}\n\n# Function for running mediation models for each level of the moderator (using mediation package)\n\nmy_mediate &lt;- function(\n  df = models_rq2_men,\n  perception,\n  gender,\n  sims = med_sims\n) {\n  if (gender == \"men\") {\n    lbl_gender &lt;- \"Men\"\n  } else {\n    lbl_gender &lt;- \"Women or Non-binary\"\n  }\n\n  set.seed(1983)\n\n  mediation::mediate(\n    model.m = df$mod_m[[perception]],\n    model.y = df$mod_y[[perception]],\n    sim = sims,\n    boot = TRUE,\n    boot.ci.type = \"bca\",\n    covariates = list(Gender = lbl_gender),\n    treat = \"Condition\",\n    mediator = \"EMA_Threat\",\n    control.value = \"Control\",\n    treat.value = \"Mindfulness\"\n  )\n}\n\nmy_mediate_no_mod &lt;- function(\n  df = models_rq2_no_mod,\n  perception,\n  sims = med_sims\n) {\n  set.seed(1983)\n\n  mediation::mediate(\n    model.m = df$mod_m[[perception]],\n    model.y = df$mod_y[[perception]],\n    sim = sims,\n    boot = TRUE,\n    boot.ci.type = \"bca\",\n    treat = \"Condition\",\n    mediator = \"EMA_Threat\",\n    control.value = \"Control\",\n    treat.value = \"Mindfulness\"\n  )\n}",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Research Question 2</span>"
    ]
  },
  {
    "objectID": "chapters/09-research-question-2.html#confidence",
    "href": "chapters/09-research-question-2.html#confidence",
    "title": "\n9  Research Question 2\n",
    "section": "\n9.2 Confidence",
    "text": "9.2 Confidence\nMen Results\nLinear Model Results\n\nShow/Hide Codetab_rq2_models(models_rq2_men, \"Confidence\")\n\n\nSupplementary Table 9.1: Mediation Analysis for Confidence at Posttest: Men\n\n\n\n\n \nModel 1 DV:Posttest Confidence\nModel 2 DV:EMA Threat\nModel 3 DV:Posttest Confidence\n\n\nPredictors\nEstimates\nSE\np\nEstimates\nSE\np\nEstimates\nSE\np\n\n\n(Intercept)\n0.07\n0.13\n0.586\n0.11\n0.13\n0.388\n0.08\n0.13\n0.545\n\n\nCondition [Mindfulness]\n-0.00\n0.17\n0.985\n-0.15\n0.16\n0.353\n-0.03\n0.17\n0.867\n\n\nGender [Women or Non-binary]\n-0.23\n0.17\n0.175\n0.02\n0.17\n0.886\n-0.25\n0.17\n0.151\n\n\nBaseline Score\n0.09\n0.06\n0.110\n0.04\n0.06\n0.443\n0.10\n0.06\n0.087\n\n\nCohort 2\n0.09\n0.10\n0.364\n-0.04\n0.10\n0.726\n0.08\n0.10\n0.423\n\n\nCohort 3\n-0.01\n0.14\n0.935\n-0.10\n0.14\n0.485\n-0.03\n0.14\n0.826\n\n\nSemester Week\n0.03\n0.15\n0.838\n-0.02\n0.14\n0.895\n0.01\n0.15\n0.919\n\n\nPosttest Test Version [B]\n-0.08\n0.11\n0.479\n0.09\n0.11\n0.392\n-0.07\n0.11\n0.540\n\n\nBaseline Threat\n-0.05\n0.07\n0.479\n0.65\n0.06\n&lt;0.001\n0.05\n0.09\n0.594\n\n\nBaseline Confidence\n0.69\n0.07\n&lt;0.001\n-0.17\n0.07\n0.015\n0.67\n0.07\n&lt;0.001\n\n\nCondition [Mindfulness] × Gender [Women or Non-binary]\n0.35\n0.22\n0.115\n-0.35\n0.22\n0.123\n0.35\n0.23\n0.128\n\n\nEMA Threat\n\n\n\n\n\n\n-0.18\n0.11\n0.115\n\n\nGender [Women or Non-binary] × EMA Threat\n\n\n\n\n\n\n0.10\n0.12\n0.420\n\n\nObservations\n148\n148\n148\n\n\nR2 / R2 adjusted\n0.589 / 0.559\n0.590 / 0.561\n0.597 / 0.561\n\n\n\n\n\n\n\nPath Diagram\n\nShow/Hide Codeplot_path_diagram(\"Confidence\", \"men\")\n\n\n\nSupplementary Figure 9.1: Mediation Analysis for Confidence at Posttest: Men\n\n\n\n\n\n\n\nMediation Test\n\nShow/Hide Codemy_mediate(perception = \"Confidence\", gender = \"men\") %&gt;% kable_mediation()\n\n\nSupplementary Table 9.2: Mediation Analysis for Confidence at Posttest: Men\n\n\n\n\n Statistic \n    Estimate \n    CI Lower \n    CI Upper \n    p \n  \n\n\n Avg. Causal Mediation Effect \n    0.03 \n    -0.02 \n    0.10 \n    0.3546 \n  \n\n Avg. Direct Effect \n    -0.03 \n    -0.32 \n    0.27 \n    0.8776 \n  \n\n Total Effect \n    0.00 \n    -0.30 \n    0.30 \n    0.9940 \n  \n\n Proportion Mediated \n    -77.28 \n    -0.29 \n    47.14 \n    0.8886 \n  \n\n\nNote.  Sample Size Used: 148; Simulations: 10000\n\n\n\n\n\n\nWomen or Non-binary Results\nLinear Model Results\n\nShow/Hide Codetab_rq2_models(models_rq2_women, \"Confidence\")\n\n\nSupplementary Table 9.3: Mediation Analysis for Confidence at Posttest: Women\n\n\n\n\n \nModel 1 DV:Posttest Confidence\nModel 2 DV:EMA Threat\nModel 3 DV:Posttest Confidence\n\n\nPredictors\nEstimates\nSE\np\nEstimates\nSE\np\nEstimates\nSE\np\n\n\n(Intercept)\n-0.16\n0.12\n0.203\n0.14\n0.12\n0.275\n-0.17\n0.13\n0.196\n\n\nCondition [Mindfulness]\n0.35\n0.15\n0.019\n-0.50\n0.15\n0.001\n0.32\n0.16\n0.044\n\n\nGender [Men]\n0.23\n0.17\n0.175\n-0.02\n0.17\n0.886\n0.25\n0.17\n0.151\n\n\nBaseline Score\n0.09\n0.06\n0.110\n0.04\n0.06\n0.443\n0.10\n0.06\n0.087\n\n\nCohort 2\n0.09\n0.10\n0.364\n-0.04\n0.10\n0.726\n0.08\n0.10\n0.423\n\n\nCohort 3\n-0.01\n0.14\n0.935\n-0.10\n0.14\n0.485\n-0.03\n0.14\n0.826\n\n\nSemester Week\n0.03\n0.15\n0.838\n-0.02\n0.14\n0.895\n0.01\n0.15\n0.919\n\n\nPosttest Test Version [B]\n-0.08\n0.11\n0.479\n0.09\n0.11\n0.392\n-0.07\n0.11\n0.540\n\n\nBaseline Threat\n-0.05\n0.07\n0.479\n0.65\n0.06\n&lt;0.001\n0.05\n0.09\n0.594\n\n\nBaseline Confidence\n0.69\n0.07\n&lt;0.001\n-0.17\n0.07\n0.015\n0.67\n0.07\n&lt;0.001\n\n\nCondition [Mindfulness] × Gender [Men]\n-0.35\n0.22\n0.115\n0.35\n0.22\n0.123\n-0.35\n0.23\n0.128\n\n\nEMA Threat\n\n\n\n\n\n\n-0.08\n0.10\n0.401\n\n\nGender [Men] × EMA Threat\n\n\n\n\n\n\n-0.10\n0.12\n0.420\n\n\nObservations\n148\n148\n148\n\n\nR2 / R2 adjusted\n0.589 / 0.559\n0.590 / 0.561\n0.597 / 0.561\n\n\n\n\n\n\n\nPath Diagram\n\nShow/Hide Codeplot_path_diagram(\"Confidence\", \"women\")\n\n\n\nSupplementary Figure 9.2: Mediation Analysis for Confidence at Posttest: Women\n\n\n\n\n\n\n\nMediation Test\n\nShow/Hide Codemy_mediate(perception = \"Confidence\", gender = \"women\") %&gt;% kable_mediation()\n\n\nSupplementary Table 9.4: Mediation Analysis for Confidence at Posttest: Women\n\n\n\n\n Statistic \n    Estimate \n    CI Lower \n    CI Upper \n    p \n  \n\n\n Avg. Causal Mediation Effect \n    0.04 \n    -0.03 \n    0.19 \n    0.3432 \n  \n\n Avg. Direct Effect \n    0.32 \n    0.01 \n    0.63 \n    0.0444 \n  \n\n Total Effect \n    0.36 \n    0.07 \n    0.67 \n    0.0140 \n  \n\n Proportion Mediated \n    0.11 \n    -0.03 \n    3.84 \n    0.3500 \n  \n\n\nNote.  Sample Size Used: 148; Simulations: 10000",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Research Question 2</span>"
    ]
  },
  {
    "objectID": "chapters/09-research-question-2.html#anxiety",
    "href": "chapters/09-research-question-2.html#anxiety",
    "title": "\n9  Research Question 2\n",
    "section": "\n9.3 Anxiety",
    "text": "9.3 Anxiety\nMen Results\nLinear Model Results\n\nShow/Hide Codetab_rq2_models(models_rq2_men, \"Anxiety\")\n\n\nSupplementary Table 9.5: Mediation Analysis for Anxiety at Posttest: Men\n\n\n\n\n \nModel 1 DV:Posttest Anxiety\nModel 2 DV:EMA Threat\nModel 3 DV:Posttest Anxiety\n\n\nPredictors\nEstimates\nSE\np\nEstimates\nSE\np\nEstimates\nSE\np\n\n\n(Intercept)\n-0.08\n0.13\n0.551\n0.12\n0.13\n0.337\n-0.11\n0.13\n0.392\n\n\nCondition [Mindfulness]\n0.00\n0.16\n0.991\n-0.16\n0.16\n0.334\n0.03\n0.16\n0.872\n\n\nGender [Women or Non-binary]\n0.24\n0.17\n0.155\n-0.01\n0.17\n0.935\n0.22\n0.17\n0.193\n\n\nBaseline Score\n-0.08\n0.06\n0.169\n0.03\n0.06\n0.624\n-0.08\n0.06\n0.145\n\n\nCohort 2\n-0.03\n0.10\n0.751\n-0.05\n0.10\n0.631\n-0.03\n0.10\n0.756\n\n\nCohort 3\n-0.04\n0.14\n0.773\n-0.12\n0.14\n0.390\n-0.03\n0.14\n0.849\n\n\nSemester Week\n-0.10\n0.14\n0.465\n-0.07\n0.14\n0.611\n-0.11\n0.14\n0.455\n\n\nPosttest Test Version [B]\n0.09\n0.11\n0.439\n0.09\n0.11\n0.427\n0.07\n0.11\n0.538\n\n\nBaseline Threat\n0.07\n0.06\n0.263\n0.67\n0.06\n&lt;0.001\n-0.05\n0.08\n0.558\n\n\nBaseline Anxiety\n0.68\n0.06\n&lt;0.001\n0.18\n0.06\n0.004\n0.65\n0.06\n&lt;0.001\n\n\nCondition [Mindfulness] × Gender [Women or Non-binary]\n-0.37\n0.22\n0.100\n-0.29\n0.22\n0.190\n-0.26\n0.22\n0.254\n\n\nEMA Threat\n\n\n\n\n\n\n0.12\n0.11\n0.268\n\n\nGender [Women or Non-binary] × EMA Threat\n\n\n\n\n\n\n0.13\n0.12\n0.261\n\n\nObservations\n148\n148\n148\n\n\nR2 / R2 adjusted\n0.589 / 0.559\n0.597 / 0.568\n0.610 / 0.575\n\n\n\n\n\n\n\nPath Diagram\n\nShow/Hide Codeplot_path_diagram(\"Anxiety\", \"men\")\n\n\n\nSupplementary Figure 9.3: Mediation Analysis for Anxiety at Posttest: Men\n\n\n\n\n\n\n\nMediation Test\n\nShow/Hide Codemy_mediate(perception = \"Anxiety\", gender = \"men\") %&gt;% kable_mediation()\n\n\nSupplementary Table 9.6: Mediation Analysis for Anxiety at Posttest: Men\n\n\n\n\n Statistic \n    Estimate \n    CI Lower \n    CI Upper \n    p \n  \n\n\n Avg. Causal Mediation Effect \n    -0.02 \n    -0.13 \n    0.01 \n    0.4680 \n  \n\n Avg. Direct Effect \n    0.03 \n    -0.29 \n    0.33 \n    0.8690 \n  \n\n Total Effect \n    0.01 \n    -0.31 \n    0.31 \n    0.9702 \n  \n\n Proportion Mediated \n    -2.98 \n    0.09 \n    2292.06 \n    0.9298 \n  \n\n\nNote.  Sample Size Used: 148; Simulations: 10000\n\n\n\n\n\n\nWomen or Non-binary Results\nLinear Model Results\n\nShow/Hide Codetab_rq2_models(models_rq2_women, \"Anxiety\")\n\n\nSupplementary Table 9.7: Mediation Analysis for Anxiety at Posttest: Women\n\n\n\n\n \nModel 1 DV:Posttest Anxiety\nModel 2 DV:EMA Threat\nModel 3 DV:Posttest Anxiety\n\n\nPredictors\nEstimates\nSE\np\nEstimates\nSE\np\nEstimates\nSE\np\n\n\n(Intercept)\n0.17\n0.13\n0.188\n0.11\n0.12\n0.377\n0.11\n0.13\n0.384\n\n\nCondition [Mindfulness]\n-0.37\n0.15\n0.015\n-0.45\n0.15\n0.003\n-0.23\n0.16\n0.140\n\n\nGender [Men]\n-0.24\n0.17\n0.155\n0.01\n0.17\n0.935\n-0.22\n0.17\n0.193\n\n\nBaseline Score\n-0.08\n0.06\n0.169\n0.03\n0.06\n0.624\n-0.08\n0.06\n0.145\n\n\nCohort 2\n-0.03\n0.10\n0.751\n-0.05\n0.10\n0.631\n-0.03\n0.10\n0.756\n\n\nCohort 3\n-0.04\n0.14\n0.773\n-0.12\n0.14\n0.390\n-0.03\n0.14\n0.849\n\n\nSemester Week\n-0.10\n0.14\n0.465\n-0.07\n0.14\n0.611\n-0.11\n0.14\n0.455\n\n\nPosttest Test Version [B]\n0.09\n0.11\n0.439\n0.09\n0.11\n0.427\n0.07\n0.11\n0.538\n\n\nBaseline Threat\n0.07\n0.06\n0.263\n0.67\n0.06\n&lt;0.001\n-0.05\n0.08\n0.558\n\n\nBaseline Anxiety\n0.68\n0.06\n&lt;0.001\n0.18\n0.06\n0.004\n0.65\n0.06\n&lt;0.001\n\n\nCondition [Mindfulness] × Gender [Men]\n0.37\n0.22\n0.100\n0.29\n0.22\n0.190\n0.26\n0.22\n0.254\n\n\nEMA Threat\n\n\n\n\n\n\n0.26\n0.10\n0.009\n\n\nGender [Men] × EMA Threat\n\n\n\n\n\n\n-0.13\n0.12\n0.261\n\n\nObservations\n148\n148\n148\n\n\nR2 / R2 adjusted\n0.589 / 0.559\n0.597 / 0.568\n0.610 / 0.575\n\n\n\n\n\n\n\nPath Diagram\n\nShow/Hide Codeplot_path_diagram(\"Anxiety\", \"women\")\n\n\n\nSupplementary Figure 9.4: Mediation Analysis for Confidence at Posttest: Women\n\n\n\n\n\n\n\nMediation Test\n\nShow/Hide Codemy_mediate(perception = \"Anxiety\", gender = \"women\") %&gt;% kable_mediation()\n\n\nSupplementary Table 9.8: Mediation Analysis for Confidence at Posttest: Women\n\n\n\n\n Statistic \n    Estimate \n    CI Lower \n    CI Upper \n    p \n  \n\n\n Avg. Causal Mediation Effect \n    -0.11 \n    -0.32 \n    -0.02 \n    0.0176 \n  \n\n Avg. Direct Effect \n    -0.23 \n    -0.55 \n    0.11 \n    0.1858 \n  \n\n Total Effect \n    -0.35 \n    -0.66 \n    -0.04 \n    0.0284 \n  \n\n Proportion Mediated \n    0.33 \n    0.02 \n    2.11 \n    0.0436 \n  \n\n\nNote.  Sample Size Used: 148; Simulations: 10000",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Research Question 2</span>"
    ]
  },
  {
    "objectID": "chapters/09-research-question-2.html#difficulty",
    "href": "chapters/09-research-question-2.html#difficulty",
    "title": "\n9  Research Question 2\n",
    "section": "\n9.4 Difficulty",
    "text": "9.4 Difficulty\nMen Results\nLinear Model Results\n\nShow/Hide Codetab_rq2_models(models_rq2_men, \"Difficulty\")\n\n\nSupplementary Table 9.9: Mediation Analysis for Difficulty at Posttest: Men\n\n\n\n\n \nModel 1 DV:Posttest Difficulty\nModel 2 DV:EMA Threat\nModel 3 DV:Posttest Difficulty\n\n\nPredictors\nEstimates\nSE\np\nEstimates\nSE\np\nEstimates\nSE\np\n\n\n(Intercept)\n0.09\n0.14\n0.519\n0.10\n0.13\n0.440\n0.09\n0.14\n0.516\n\n\nCondition [Mindfulness]\n-0.47\n0.18\n0.009\n-0.17\n0.16\n0.298\n-0.47\n0.18\n0.009\n\n\nGender [Women or Non-binary]\n0.16\n0.18\n0.377\n0.05\n0.17\n0.763\n0.16\n0.18\n0.380\n\n\nBaseline Score\n-0.04\n0.06\n0.465\n0.04\n0.06\n0.496\n-0.04\n0.06\n0.474\n\n\nCohort 2\n-0.15\n0.11\n0.166\n-0.03\n0.10\n0.747\n-0.15\n0.11\n0.170\n\n\nCohort 3\n-0.18\n0.15\n0.243\n-0.09\n0.14\n0.527\n-0.18\n0.16\n0.246\n\n\nSemester Week\n-0.12\n0.15\n0.446\n-0.02\n0.15\n0.880\n-0.12\n0.16\n0.454\n\n\nPosttest Test Version [B]\n0.05\n0.12\n0.669\n0.09\n0.11\n0.426\n0.05\n0.12\n0.664\n\n\nBaseline Threat\n-0.01\n0.07\n0.891\n0.68\n0.06\n&lt;0.001\n0.00\n0.09\n0.995\n\n\nBaseline Difficulty\n0.66\n0.07\n&lt;0.001\n0.15\n0.06\n0.018\n0.67\n0.07\n&lt;0.001\n\n\nCondition [Mindfulness] × Gender [Women or Non-binary]\n0.12\n0.24\n0.609\n-0.31\n0.22\n0.165\n0.12\n0.25\n0.639\n\n\nEMA Threat\n\n\n\n\n\n\n-0.01\n0.12\n0.916\n\n\nGender [Women or Non-binary] × EMA Threat\n\n\n\n\n\n\n-0.00\n0.13\n0.976\n\n\nObservations\n148\n148\n148\n\n\nR2 / R2 adjusted\n0.535 / 0.501\n0.590 / 0.560\n0.535 / 0.493\n\n\n\n\n\n\n\nPath Diagram\n\nShow/Hide Codeplot_path_diagram(\"Difficulty\", \"men\")\n\n\n\nSupplementary Figure 9.5: Mediation Analysis for Difficulty at Posttest: Men\n\n\n\n\n\n\n\nMediation Test\n\nShow/Hide Codemy_mediate(perception = \"Difficulty\", gender = \"men\") %&gt;% kable_mediation()\n\n\nSupplementary Table 9.10: Mediation Analysis for Difficulty at Posttest: Men\n\n\n\n\n Statistic \n    Estimate \n    CI Lower \n    CI Upper \n    p \n  \n\n\n Avg. Causal Mediation Effect \n    0.00 \n    -0.03 \n    0.09 \n    0.8944 \n  \n\n Avg. Direct Effect \n    -0.47 \n    -0.80 \n    -0.13 \n    0.0070 \n  \n\n Total Effect \n    -0.47 \n    -0.79 \n    -0.13 \n    0.0064 \n  \n\n Proportion Mediated \n    0.00 \n    -0.31 \n    0.06 \n    0.8940 \n  \n\n\nNote.  Sample Size Used: 148; Simulations: 10000\n\n\n\n\n\n\nWomen or Non-binary Results\nLinear Model Results\n\nShow/Hide Codetab_rq2_models(models_rq2_women, \"Difficulty\")\n\n\nSupplementary Table 9.11: Mediation Analysis for Difficulty at Posttest: Women\n\n\n\n\n \nModel 1 DV:Posttest Difficulty\nModel 2 DV:EMA Threat\nModel 3 DV:Posttest Difficulty\n\n\nPredictors\nEstimates\nSE\np\nEstimates\nSE\np\nEstimates\nSE\np\n\n\n(Intercept)\n0.25\n0.13\n0.063\n0.15\n0.12\n0.225\n0.25\n0.14\n0.070\n\n\nCondition [Mindfulness]\n-0.34\n0.16\n0.031\n-0.48\n0.15\n0.001\n-0.35\n0.17\n0.040\n\n\nGender [Men]\n-0.16\n0.18\n0.377\n-0.05\n0.17\n0.763\n-0.16\n0.18\n0.380\n\n\nBaseline Score\n-0.04\n0.06\n0.465\n0.04\n0.06\n0.496\n-0.04\n0.06\n0.474\n\n\nCohort 2\n-0.15\n0.11\n0.166\n-0.03\n0.10\n0.747\n-0.15\n0.11\n0.170\n\n\nCohort 3\n-0.18\n0.15\n0.243\n-0.09\n0.14\n0.527\n-0.18\n0.16\n0.246\n\n\nSemester Week\n-0.12\n0.15\n0.446\n-0.02\n0.15\n0.880\n-0.12\n0.16\n0.454\n\n\nPosttest Test Version [B]\n0.05\n0.12\n0.669\n0.09\n0.11\n0.426\n0.05\n0.12\n0.664\n\n\nBaseline Threat\n-0.01\n0.07\n0.891\n0.68\n0.06\n&lt;0.001\n0.00\n0.09\n0.995\n\n\nBaseline Difficulty\n0.66\n0.07\n&lt;0.001\n0.15\n0.06\n0.018\n0.67\n0.07\n&lt;0.001\n\n\nCondition [Mindfulness] × Gender [Men]\n-0.12\n0.24\n0.609\n0.31\n0.22\n0.165\n-0.12\n0.25\n0.639\n\n\nEMA Threat\n\n\n\n\n\n\n-0.02\n0.10\n0.875\n\n\nGender [Men] × EMA Threat\n\n\n\n\n\n\n0.00\n0.13\n0.976\n\n\nObservations\n148\n148\n148\n\n\nR2 / R2 adjusted\n0.535 / 0.501\n0.590 / 0.560\n0.535 / 0.493\n\n\n\n\n\n\n\nPath Diagram\n\nShow/Hide Codeplot_path_diagram(\"Difficulty\", \"women\")\n\n\n\nSupplementary Figure 9.6: Mediation Analysis for Difficulty at Posttest: Women\n\n\n\n\n\n\n\nMediation Test\n\nShow/Hide Codemy_mediate(perception = \"Difficulty\", gender = \"women\") %&gt;% kable_mediation()\n\n\nSupplementary Table 9.12: Mediation Analysis for Difficulty at Posttest: Women\n\n\n\n\n Statistic \n    Estimate \n    CI Lower \n    CI Upper \n    p \n  \n\n\n Avg. Causal Mediation Effect \n    0.01 \n    -0.13 \n    0.13 \n    0.9034 \n  \n\n Avg. Direct Effect \n    -0.35 \n    -0.70 \n    -0.03 \n    0.0320 \n  \n\n Total Effect \n    -0.34 \n    -0.66 \n    -0.05 \n    0.0254 \n  \n\n Proportion Mediated \n    -0.02 \n    -0.66 \n    0.55 \n    0.9068 \n  \n\n\nNote.  Sample Size Used: 148; Simulations: 10000",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Research Question 2</span>"
    ]
  },
  {
    "objectID": "chapters/09-research-question-2.html#sec-preregistered",
    "href": "chapters/09-research-question-2.html#sec-preregistered",
    "title": "\n9  Research Question 2\n",
    "section": "\n9.5 Unmoderated Mediation Results (preregistered analyses)",
    "text": "9.5 Unmoderated Mediation Results (preregistered analyses)\nConfidence\nLinear Models\n\nShow/Hide Codetab_rq2_models(models_rq2_no_mod, \"Confidence\")\n\n\nSupplementary Table 9.13: Mediation Analysis for Confidence at Posttest without Gender Moderation\n\n\n\n\n \nModel 1 DV:Posttest Confidence\nModel 2 DV:EMA Threat\nModel 3 DV:Posttest Confidence\n\n\nPredictors\nEstimates\nSE\np\nEstimates\nSE\np\nEstimates\nSE\np\n\n\n(Intercept)\n-0.03\n0.12\n0.828\n0.21\n0.12\n0.076\n0.00\n0.12\n0.982\n\n\nCondition [Mindfulness]\n0.19\n0.11\n0.083\n-0.35\n0.11\n0.002\n0.15\n0.11\n0.200\n\n\nGender [Women or Non-binary]\n-0.05\n0.12\n0.708\n-0.16\n0.12\n0.210\n-0.07\n0.12\n0.587\n\n\nBaseline Score\n0.09\n0.06\n0.116\n0.04\n0.06\n0.435\n0.10\n0.06\n0.093\n\n\nCohort 2\n0.10\n0.10\n0.351\n-0.04\n0.10\n0.705\n0.09\n0.10\n0.375\n\n\nCohort 3\n-0.01\n0.15\n0.966\n-0.11\n0.14\n0.464\n-0.02\n0.14\n0.887\n\n\nSemester Week\n0.03\n0.15\n0.812\n-0.02\n0.15\n0.868\n0.03\n0.15\n0.828\n\n\nPosttest Test Version [B]\n-0.09\n0.11\n0.406\n0.11\n0.11\n0.329\n-0.08\n0.11\n0.483\n\n\nBaseline Threat\n-0.06\n0.06\n0.349\n0.67\n0.06\n&lt;0.001\n0.03\n0.09\n0.734\n\n\nBaseline Confidence\n0.68\n0.07\n&lt;0.001\n-0.16\n0.07\n0.021\n0.66\n0.07\n&lt;0.001\n\n\nEMA Threat\n\n\n\n\n\n\n-0.13\n0.08\n0.114\n\n\nObservations\n148\n148\n148\n\n\nR2 / R2 adjusted\n0.581 / 0.554\n0.583 / 0.556\n0.589 / 0.559\n\n\n\n\n\n\n\nPath Diagram\n\nShow/Hide Codeplot_path_diagram(\"Confidence\", \"no_mod\")\n\n\n\nSupplementary Figure 9.7: Mediation Analysis for Confidence at Posttest without Gender Moderation\n\n\n\n\n\n\n\nMediation Test\n\nShow/Hide Codemy_mediate_no_mod(perception = \"Confidence\") |&gt; kable_mediation()\n\n\nSupplementary Table 9.14: Mediation Analysis for Confidence at Posttest without Gender Moderation\n\n\n\n\n Statistic \n    Estimate \n    CI Lower \n    CI Upper \n    p \n  \n\n\n Avg. Causal Mediation Effect \n    0.05 \n    0.00 \n    0.13 \n    0.0610 \n  \n\n Avg. Direct Effect \n    0.15 \n    -0.07 \n    0.37 \n    0.1890 \n  \n\n Total Effect \n    0.19 \n    -0.02 \n    0.42 \n    0.0816 \n  \n\n Proportion Mediated \n    0.24 \n    0.16 \n    25.32 \n    0.1370 \n  \n\n\nNote.  Sample Size Used: 148; Simulations: 10000\n\n\n\n\n\n\nAnxiety\nLinear Models\n\nShow/Hide Codetab_rq2_models(models_rq2_no_mod, \"Anxiety\")\n\n\nSupplementary Table 9.15: Mediation Analysis for Anxiety at Posttest without Gender Moderation\n\n\n\n\n \nModel 1 DV:Posttest Anxiety\nModel 2 DV:EMA Threat\nModel 3 DV:Posttest Anxiety\n\n\nPredictors\nEstimates\nSE\np\nEstimates\nSE\np\nEstimates\nSE\np\n\n\n(Intercept)\n0.02\n0.12\n0.836\n0.20\n0.11\n0.075\n-0.02\n0.11\n0.857\n\n\nCondition [Mindfulness]\n-0.20\n0.11\n0.073\n-0.32\n0.11\n0.004\n-0.13\n0.11\n0.244\n\n\nGender [Women or Non-binary]\n0.05\n0.12\n0.697\n-0.17\n0.12\n0.169\n0.08\n0.12\n0.487\n\n\nBaseline Score\n-0.08\n0.06\n0.179\n0.03\n0.06\n0.611\n-0.08\n0.06\n0.139\n\n\nCohort 2\n-0.03\n0.10\n0.738\n-0.05\n0.10\n0.621\n-0.02\n0.10\n0.816\n\n\nCohort 3\n-0.05\n0.15\n0.748\n-0.13\n0.14\n0.376\n-0.02\n0.14\n0.894\n\n\nSemester Week\n-0.11\n0.14\n0.462\n-0.07\n0.14\n0.606\n-0.09\n0.14\n0.524\n\n\nPosttest Test Version [B]\n0.10\n0.11\n0.363\n0.10\n0.11\n0.365\n0.08\n0.11\n0.467\n\n\nBaseline Threat\n0.08\n0.06\n0.195\n0.68\n0.06\n&lt;0.001\n-0.07\n0.08\n0.405\n\n\nBaseline Anxiety\n0.68\n0.06\n&lt;0.001\n0.18\n0.06\n0.004\n0.65\n0.06\n&lt;0.001\n\n\nEMA Threat\n\n\n\n\n\n\n0.22\n0.08\n0.011\n\n\nObservations\n148\n148\n148\n\n\nR2 / R2 adjusted\n0.581 / 0.554\n0.592 / 0.566\n0.601 / 0.571\n\n\n\n\n\n\n\nPath Diagram\n\nShow/Hide Codeplot_path_diagram(\"Anxiety\", \"no_mod\")\n\n\n\nSupplementary Figure 9.8: Mediation Analysis for Anxiety at Posttest without Gender Moderation\n\n\n\n\n\n\n\nMediation Test\n\nShow/Hide Codemy_mediate_no_mod(perception = \"Anxiety\") |&gt; kable_mediation()\n\n\nSupplementary Table 9.16: Mediation Analysis for Anxiety at Posttest without Gender Moderation\n\n\n\n\n Statistic \n    Estimate \n    CI Lower \n    CI Upper \n    p \n  \n\n\n Avg. Causal Mediation Effect \n    -0.07 \n    -0.18 \n    -0.01 \n    0.0202 \n  \n\n Avg. Direct Effect \n    -0.13 \n    -0.36 \n    0.10 \n    0.2546 \n  \n\n Total Effect \n    -0.20 \n    -0.42 \n    0.02 \n    0.0784 \n  \n\n Proportion Mediated \n    0.35 \n    -0.44 \n    3.16 \n    0.0930 \n  \n\n\nNote.  Sample Size Used: 148; Simulations: 10000\n\n\n\n\n\n\nDifficulty\nLinear Models\n\nShow/Hide Codetab_rq2_models(models_rq2_no_mod, \"Difficulty\")\n\n\nSupplementary Table 9.17: Mediation Analysis for Difficulty at Posttest without Gender Moderation\n\n\n\n\n \nModel 1 DV:Posttest Difficulty\nModel 2 DV:EMA Threat\nModel 3 DV:Posttest Difficulty\n\n\nPredictors\nEstimates\nSE\np\nEstimates\nSE\np\nEstimates\nSE\np\n\n\n(Intercept)\n0.06\n0.12\n0.647\n0.19\n0.11\n0.108\n0.06\n0.12\n0.629\n\n\nCondition [Mindfulness]\n-0.40\n0.12\n0.001\n-0.34\n0.11\n0.002\n-0.41\n0.12\n0.001\n\n\nGender [Women or Non-binary]\n0.22\n0.13\n0.082\n-0.11\n0.12\n0.346\n0.22\n0.13\n0.087\n\n\nBaseline Score\n-0.04\n0.06\n0.459\n0.04\n0.06\n0.484\n-0.04\n0.06\n0.469\n\n\nCohort 2\n-0.15\n0.11\n0.167\n-0.04\n0.10\n0.733\n-0.15\n0.11\n0.167\n\n\nCohort 3\n-0.18\n0.15\n0.246\n-0.10\n0.15\n0.508\n-0.18\n0.15\n0.243\n\n\nSemester Week\n-0.12\n0.15\n0.448\n-0.02\n0.15\n0.869\n-0.12\n0.15\n0.448\n\n\nPosttest Test Version [B]\n0.05\n0.12\n0.699\n0.10\n0.11\n0.362\n0.05\n0.12\n0.688\n\n\nBaseline Threat\n-0.01\n0.06\n0.842\n0.69\n0.06\n&lt;0.001\n0.00\n0.09\n0.991\n\n\nBaseline Difficulty\n0.67\n0.07\n&lt;0.001\n0.15\n0.06\n0.020\n0.67\n0.07\n&lt;0.001\n\n\nEMA Threat\n\n\n\n\n\n\n-0.02\n0.09\n0.823\n\n\nObservations\n148\n148\n148\n\n\nR2 / R2 adjusted\n0.534 / 0.503\n0.584 / 0.557\n0.534 / 0.500\n\n\n\n\n\n\n\nPath Diagram\n\nShow/Hide Codeplot_path_diagram(\"Difficulty\", \"no_mod\")\n\n\n\nSupplementary Figure 9.9: Mediation Analysis for Difficulty at Posttest without Gender Moderation\n\n\n\n\n\n\n\nMediation Test\n\nShow/Hide Codemy_mediate_no_mod(perception = \"Difficulty\") |&gt; kable_mediation()\n\n\nSupplementary Table 9.18: Mediation Analysis for Difficulty at Posttest without Gender Moderation\n\n\n\n\n Statistic \n    Estimate \n    CI Lower \n    CI Upper \n    p \n  \n\n\n Avg. Causal Mediation Effect \n    0.01 \n    -0.06 \n    0.08 \n    0.8550 \n  \n\n Avg. Direct Effect \n    -0.41 \n    -0.65 \n    -0.17 \n    0.0012 \n  \n\n Total Effect \n    -0.40 \n    -0.63 \n    -0.18 \n    0.0004 \n  \n\n Proportion Mediated \n    -0.02 \n    -0.26 \n    0.17 \n    0.8550 \n  \n\n\nNote.  Sample Size Used: 148; Simulations: 10000",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Research Question 2</span>"
    ]
  },
  {
    "objectID": "chapters/10-accuracy-results.html",
    "href": "chapters/10-accuracy-results.html",
    "title": "\n10  Physics Task Accuracy\n",
    "section": "",
    "text": "10.1 Model Specification\nThe tables below show that there was no effect of mindfulness training on physics task accuracy (Supplementary Table 10.1) or learning on the PFL (Supplementary Table 10.2).\nShow/Hide Code# Accuracy by problem solving task for parts 1-3\n\ndata_accuracy &lt;- data_rq1 %&gt;%\n  filter(Part != \"PFL\") %&gt;%\n  pivot_wider(\n    names_from = perception,\n    values_from = rating\n  ) %&gt;%\n  group_by(\n    Participant,\n    Condition,\n    Gender,\n    Cohort,\n    Timepoint,\n    Semester_Week,\n    Test_Version,\n    Part,\n    Baseline_Threat,\n    EMA_Threat\n  ) %&gt;%\n  summarise(Score = mean(Score), .groups = \"drop\")\n\nmodels_accuracy &lt;- data_accuracy %&gt;%\n  group_by(Part) %&gt;%\n  nest %&gt;%\n  mutate(\n    # Models with all covariates included\n    mod_full = map(\n      data,\n      ~ lmer(\n        Score ~\n          Cohort +\n            Semester_Week +\n            Test_Version +\n            Baseline_Threat +\n            Gender +\n            Timepoint * Condition +\n            (1 | Participant),\n        data = .x\n      )\n    ),\n    # Models with no covariates\n    mod_cov_removed = map(\n      data,\n      ~ lmer(\n        Score ~ Timepoint * Condition * Gender + (1 | Participant),\n        data = .x\n      )\n    ),\n    # Models with gender interaction\n    mod_gender_interact = map(\n      data,\n      ~ lmer(\n        Score ~\n          Cohort +\n            Semester_Week +\n            Test_Version +\n            Baseline_Threat +\n            Timepoint * Condition * Gender +\n            (1 | Participant),\n        data = .x\n      )\n    ),\n    # Empty means models (only random effects)\n    mod_empty_means = map(\n      data,\n      ~ lmer(\n        Score ~ (1 | Participant),\n        data = .x\n      )\n    ),\n    # Compare 2-way and 3-way interaction models\n    comparison = pmap(list(mod_full, mod_gender_interact), anova)\n  ) %&gt;%\n  name_list_columns() # Name the list columns\n\n# Accuracy on the PFL Task\n\ndata_pfl &lt;- data_rq1 %&gt;%\n  filter(Part == \"PFL\") %&gt;%\n  pivot_wider(names_from = perception, values_from = rating) %&gt;%\n  mutate(\n    Question = factor(Question - 10),\n    Score = factor(Score)\n  )\n\nmodel_pfl &lt;- glmer(\n  Score ~\n    Cohort +\n      Semester_Week +\n      Baseline_Threat +\n      Gender +\n      Question * Condition +\n      (1 | Participant),\n  data = data_pfl,\n  family = \"binomial\",\n  control = glmerControl(optimizer = \"bobyqa\")\n)",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Physics Task Accuracy</span>"
    ]
  },
  {
    "objectID": "chapters/10-accuracy-results.html#preregistered-hypotheses-1-and-4",
    "href": "chapters/10-accuracy-results.html#preregistered-hypotheses-1-and-4",
    "title": "\n10  Physics Task Accuracy\n",
    "section": "\n10.2 Preregistered Hypotheses 1 and 4",
    "text": "10.2 Preregistered Hypotheses 1 and 4\n\nShow/Hide Code# tab_model(\n#   models_accuracy$mod_full$Quantitative,\n#   models_accuracy$mod_full$Categorization,\n#   models_accuracy$mod_full$Qualitative,\n#   show.se = T,\n#   string.se = \"SE\",\n#   show.ci = F,\n#   dv.labels = c(\"Quantitative\", \"Categorization\", \"Qualitative\") |&gt;\n#     (\\(x) paste0(\"Part\", 1:3, \": \", x))()\n# )\n\nhandle_model_print(\n  list(\n    models_accuracy$mod_full$Quantitative,\n    models_accuracy$mod_full$Categorization,\n    models_accuracy$mod_full$Qualitative\n  ),\n  c(\"Quantitative\", \"Categorization\", \"Qualitative\") |&gt;\n    (\\(x) paste0(\"Part\", 1:3, \": \", x))(),\n  n_models = 3,\n  is_lmer = TRUE,\n  raneff_rownum = 11\n)\n\n\nSupplementary Table 10.1: Results from Mixed Effects Models Testing Preregistered Hypotheses 1 and 4: Effects of Mindfulness Training on Problem Solving Accuracy\n\n\n\n\n \nPart1: Quantitative\nPart2: Categorization\nPart3: Qualitative\n\n\nPredictors\nEstimates\nSE\np\nEstimates\nSE\np\nEstimates\nSE\np\n\n\n(Intercept)\n0.07\n0.01\n&lt;0.001\n0.38\n0.02\n&lt;0.001\n0.50\n0.02\n&lt;0.001\n\n\nCohort [Cohort 2]\n0.01\n0.06\n0.902\n-0.11\n0.08\n0.178\n-0.10\n0.08\n0.222\n\n\nCohort [Cohort 3]\n0.07\n0.05\n0.213\n-0.03\n0.07\n0.630\n-0.08\n0.07\n0.288\n\n\nSemester Week\n0.01\n0.01\n0.339\n-0.00\n0.01\n0.750\n0.01\n0.01\n0.675\n\n\nTest Version [B]\n0.03\n0.02\n0.092\n-0.10\n0.02\n&lt;0.001\n0.21\n0.02\n&lt;0.001\n\n\nBaseline Threat\n-0.04\n0.01\n&lt;0.001\n-0.00\n0.01\n0.766\n-0.03\n0.01\n0.008\n\n\nGender [Women or Non-binary]\n0.02\n0.02\n0.344\n-0.01\n0.03\n0.774\n-0.06\n0.03\n0.033\n\n\nTimepoint [Posttest]\n0.01\n0.02\n0.545\n-0.03\n0.02\n0.205\n0.07\n0.02\n0.003\n\n\nCondition [Mindfulness]\n0.02\n0.03\n0.385\n0.04\n0.04\n0.292\n-0.06\n0.04\n0.083\n\n\nTimepoint [Posttest] × Condition [Mindfulness]\n-0.02\n0.04\n0.558\n-0.05\n0.04\n0.277\n0.04\n0.05\n0.369\n\n\nRandom Effects\n\n\nσ2\n\n0.03\n0.04\n0.04\n\n\nτ00\n\n0.00 Participant\n\n0.01 Participant\n\n0.01 Participant\n\n\n\n\nICC\n0.04\n0.20\n0.15\n\n\n\nN\n149 Participant\n\n149 Participant\n\n149 Participant\n\n\n\nObservations\n295\n298\n298\n\n\nMarginal R2 / Conditional R2\n\n0.095 / 0.135\n0.072 / 0.259\n0.274 / 0.380\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSupplementary Table 10.1: The estimates for the intercept represent the overall mean score (percent correct) and standard errors for each of the problem solving performance outcomes at baseline. The estimate for timepoint represents the change in the dependent variable from baseline to posttest across",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Physics Task Accuracy</span>"
    ]
  },
  {
    "objectID": "chapters/10-accuracy-results.html#preregistered-hypothesis-5",
    "href": "chapters/10-accuracy-results.html#preregistered-hypothesis-5",
    "title": "\n10  Physics Task Accuracy\n",
    "section": "\n10.3 Preregistered Hypothesis 5",
    "text": "10.3 Preregistered Hypothesis 5\n\nShow/Hide Code# tab_model(\n#   model_pfl,\n#   show.se = T,\n#   string.se = \"SE\",\n#   show.ci = F,\n#   dv.labels = \"PFL Correctness\"\n# )\n\nhandle_model_print(\n  list(\n    model_pfl\n  ),\n  \"PFL Correctness\",\n  n_models = 1,\n  is_lmer = TRUE,\n  raneff_rownum = 10,\n  str_estimate = \"Odds Ratios\"\n)\n\n\nSupplementary Table 10.2: Results from Logistic Mixed Effects Model Testing Preregistered Hypothesis 5: Effects of Mindfulness Training on Learning During the Preparation for Future Learning Task\n\n\n\n\n \nPFL Correctness\n\n\nPredictors\nOdds Ratios\nSE\np\n\n\n(Intercept)\n0.23\n0.06\n&lt;0.001\n\n\nCohort [Cohort 2]\n1.13\n1.04\n0.894\n\n\nCohort [Cohort 3]\n0.51\n0.41\n0.403\n\n\nSemester Week\n1.10\n0.16\n0.521\n\n\nBaseline Threat\n0.86\n0.11\n0.234\n\n\nGender [Women or Non-binary]\n0.37\n0.13\n0.005\n\n\nQuestion [2]\n4.87\n1.59\n&lt;0.001\n\n\nCondition [Mindfulness]\n1.42\n0.64\n0.433\n\n\nQuestion [2] × Condition [Mindfulness]\n0.91\n0.52\n0.873\n\n\nRandom Effects\n\n\nσ2\n\n3.29\n\n\nτ00Participant\n\n0.62\n\n\n\nICC\n0.16\n\n\n\nN Participant\n\n149\n\n\nObservations\n298\n\n\nMarginal R2 / Conditional R2\n\n0.235 / 0.356\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSupplementary Table 10.2: The odds ratio for the intercept term represents the odds of getting question 1 correct compared to incorrect. The odds ratio for the question × condition interaction term represents the difference in odds of getting question 2 correct between conditions, above and beyond any condition differences on question 1 and overall differences on question 2, compared to question 1. P-values below .05 are indicated by bold font.",
    "crumbs": [
      "R Code and Analyses",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Physics Task Accuracy</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Belenky, Daniel M, and Timothy J Nokes-Malach. 2012. “Motivation\nand Transfer: The Role of Mastery-Approach Goals in Preparation for\nFuture Learning.” The Journal of the Learning Sciences\n21 (3): 399–432. https://doi.org/10.1080/10508406.2011.651232.\n\n\nHardiman, Pamela Thibodeau, Robert Dufresne, and Jose P Mestre. 1989.\n“The Relation Between Problem Categorization and Problem Solving\nAmong Experts and Novices.” Memory & Cognition 17\n(5): 627–38.\n\n\nSchwartz, Daniel L, and Taylor Martin. 2004. “Inventing to Prepare\nfor Future Learning: The Hidden Efficiency of Encouraging Original\nStudent Production in Statistics Instruction.” Cognition and\nInstruction 22 (2): 129–84.\n\n\nWeinlader, Nolan K., Eric Kuo, Benjamin M. Rottman, and Timothy J.\nNokes-Malach. 2019. “A New Approach for Uncovering Student\nResources with Multiple-Choice Questions.” In, 621–26. American\nAssociation of Physics Teachers. https://doi.org/10.1119/perc.2019.pr.Weinlader.",
    "crumbs": [
      "References"
    ]
  }
]